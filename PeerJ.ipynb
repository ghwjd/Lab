{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-03 00:01:36.165676: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-03 00:01:36.286982: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        # logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        # print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기 및 클래스 지정과 분할  \n",
    "The numbers of samples in each class for the test set are distributed as 106 (normal), 24 (AOM), 13 (CSOM), 28 (Earwax), and 20 (Other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 데이터셋의 루트 디렉토리\n",
    "dataset_directory = '/home/jeonk636/ear_classification/eardrumDs'\n",
    "\n",
    "# 클래스 이름 및 라벨을 매핑하기 위한 딕셔너리 생성\n",
    "# normal:0, Aom:1, Chornic:2, Earwax:3, Others:4\n",
    "label_map = {\n",
    "    'Aom': 1,\n",
    "    'Chornic': 2,\n",
    "    'Earwax': 3,\n",
    "    'Normal': 0,\n",
    "    'OtitExterna': 4,\n",
    "    'tympanoskleros': 4,\n",
    "    'Earventulation': 4,\n",
    "    'Foreign': 4,\n",
    "    'PseduoMembran': 4\n",
    "}\n",
    "\n",
    "# 이미지 파일 경로 및 라벨을 저장할 리스트\n",
    "image_paths = []\n",
    "image_labels = []\n",
    "\n",
    "# 각 폴더에 대해 이미지 파일 경로 및 해당 라벨을 리스트에 추가\n",
    "for label_folder in os.listdir(dataset_directory):\n",
    "    folder_path = os.path.join(dataset_directory, label_folder)\n",
    "    \n",
    "    for image_filename in os.listdir(folder_path):\n",
    "        # 폴더 내 파일이 실제 파일인지 확인하고 '.ipynb_checkpoints' 폴더를 건너뛴다.\n",
    "        full_path = os.path.join(folder_path, image_filename)\n",
    "        if os.path.isfile(full_path) and '.ipynb_checkpoints' not in full_path:\n",
    "            image_paths.append(full_path)\n",
    "            image_labels.append(label_map[label_folder])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal: 534\n",
      "Aom: 119\n",
      "Chornic: 63\n",
      "Earwax: 140\n",
      "Others: 99\n"
     ]
    }
   ],
   "source": [
    "label_0_count = image_labels.count(0)\n",
    "label_1_count = image_labels.count(1)\n",
    "label_2_count = image_labels.count(2)\n",
    "label_3_count = image_labels.count(3)\n",
    "label_4_count = image_labels.count(4)\n",
    "\n",
    "print('Normal:', label_0_count)\n",
    "print('Aom:', label_1_count)\n",
    "print('Chornic:', label_2_count)\n",
    "print('Earwax:', label_3_count)\n",
    "print('Others:', label_4_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# 이미지 경로와 라벨을 Numpy 배열로 변환\n",
    "image_paths = np.array(image_paths)\n",
    "image_labels = np.array(image_labels)\n",
    "\n",
    "# 데이터프레임으로 변환\n",
    "data = pd.DataFrame({'image_path': image_paths, 'label': image_labels})\n",
    "\n",
    "# 클래스별로 지정된 수의 샘플을 추출하여 테스트 세트로 사용\n",
    "test_counts = {\n",
    "    0: 106,  # Normal\n",
    "    1: 24,   # AOM\n",
    "    2: 13,   # CSOM\n",
    "    3: 28,   # Earwax\n",
    "    4: 20    # Other\n",
    "}\n",
    "\n",
    "test_data_list = []\n",
    "\n",
    "for label, count in test_counts.items():\n",
    "    class_data = data[data['label'] == label]\n",
    "    if len(class_data) < count:\n",
    "        raise ValueError(f\"Not enough samples for class {label}. Needed {count}, but only {len(class_data)} available.\")\n",
    "    test_data_list.append(class_data.sample(n=count, random_state=42))\n",
    "\n",
    "test_data = pd.concat(test_data_list)\n",
    "\n",
    "# 나머지 데이터를 훈련 세트로 사용\n",
    "train_data = data.drop(test_data.index)\n",
    "\n",
    "# 훈련 세트와 테스트 세트로 나누기\n",
    "x_train = train_data['image_path'].values\n",
    "y_train = train_data['label'].values\n",
    "x_test = test_data['image_path'].values\n",
    "y_test = test_data['label'].values\n",
    "\n",
    "# # train 8: validation 2 분할\n",
    "# x_train, x_test, y_train, y_test = train_test_split(\n",
    "#     image_paths, image_labels, stratify=image_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Train set:\", len(x_train))\n",
    "# print(\"test set:\", len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 764\n",
      "Test set size: 191\n",
      "Test set class distribution:\n",
      " label\n",
      "0    106\n",
      "3     28\n",
      "1     24\n",
      "4     20\n",
      "2     13\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(\"Training set size:\", len(x_train))\n",
    "print(\"Test set size:\", len(x_test))\n",
    "print(\"Test set class distribution:\\n\", test_data['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras을 사용한 데이터 증강  \n",
    "224 by 224  \n",
    "Normal 클래스가 가장 많은 샘플 수를 가지고 있으므로, 이를 기준으로 AOM, CSOM, Earwax, Other 클래스을 각각 3배, 7배, 3배, 4배 증강  \n",
    "증강을 하면 train set에 있는 total sample 수는 normal 428, Aom 380, Csom 400, Earwax 448, others 395으로 각 클래스가 비슷해짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 데이터 증강 파라미터 정의\n",
    "data_gen_args = dict(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.7, 1.3],  # ±30% 밝기 조절\n",
    "    width_shift_range=0.2,  # 좌우 이동 범위 20%\n",
    "    height_shift_range=0.2,  # 상하 이동 범위 20%\n",
    "    zoom_range=0.2,  # ±20% 확대/축소\n",
    "    rotation_range=20  # ±20도 회전\n",
    ")\n",
    "\n",
    "# 데이터 증강 제네레이터 생성\n",
    "datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "# 증강된 샘플 수를 지정\n",
    "augment_counts = {\n",
    "    1: 3,  # AOM\n",
    "    2: 7,  # CSOM\n",
    "    3: 3,  # Earwax\n",
    "    4: 4   # Other\n",
    "}\n",
    "\n",
    "# 증강된 데이터를 저장할 리스트\n",
    "augmented_data = []\n",
    "\n",
    "for label, count in augment_counts.items():\n",
    "    class_data = train_data[train_data['label'] == label]\n",
    "    for i in range(count):\n",
    "        for index, row in class_data.iterrows():\n",
    "            img = tf.keras.preprocessing.image.load_img(row['image_path'], target_size=(224, 224))\n",
    "            img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "            augmented_iter = datagen.flow(img_array, batch_size=1)\n",
    "            augmented_img = next(augmented_iter)[0].astype(np.uint8)\n",
    "            augmented_data.append({'image_path': row['image_path'], 'label': row['label']})\n",
    "\n",
    "# 원본 데이터와 증강 데이터를 결합\n",
    "augmented_df = pd.DataFrame(augmented_data)\n",
    "train_data = pd.concat([train_data, augmented_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "3    448\n",
      "0    428\n",
      "2    400\n",
      "4    395\n",
      "1    380\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "2    350\n",
      "3    336\n",
      "4    316\n",
      "1    285\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "print(train_data['label'].value_counts())\n",
    "print(augmented_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
