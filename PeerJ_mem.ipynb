{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gpu 메모리 부족 현상이 발생해서 이에 대한 새로운 접근\n",
    "mini_batch size: 24->12  \n",
    "upsampling: (4,4) -> (2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 10:24:58.324542: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-05 10:24:58.451290: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPUs will likely run quickly with dtype policy mixed_float16 as they all have compute capability of at least 7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "# mixed precision 설정\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "# GPU 설정\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  4\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기 및 클래스 지정과 분할  \n",
    "The numbers of samples in each class for the test set are distributed as 106 (normal), 24 (AOM), 13 (CSOM), 28 (Earwax), and 20 (Other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 데이터셋의 루트 디렉토리\n",
    "dataset_directory = '/home/jeonk636/ear_classification/eardrumDs'\n",
    "\n",
    "# 클래스 이름 및 라벨을 매핑하기 위한 딕셔너리 생성\n",
    "# normal:0, Aom:1, Chornic:2, Earwax:3, Others:4\n",
    "label_map = {\n",
    "    'Aom': 1,\n",
    "    'Chornic': 2,\n",
    "    'Earwax': 3,\n",
    "    'Normal': 0,\n",
    "}\n",
    "\n",
    "# 이미지 파일 경로 및 라벨을 저장할 리스트\n",
    "image_paths = []\n",
    "image_labels = []\n",
    "\n",
    "exclude_folders = {'OtitExterna', 'tympanoskleros', 'Earventulation', 'Foreign', 'PseduoMembran'}\n",
    "\n",
    "# 각 폴더에 대해 이미지 파일 경로 및 해당 라벨을 리스트에 추가\n",
    "for label_folder in os.listdir(dataset_directory):\n",
    "    if label_folder in exclude_folders:  # 이 폴더는 건너뛴다.\n",
    "        continue\n",
    "    folder_path = os.path.join(dataset_directory, label_folder)\n",
    "    \n",
    "    for image_filename in os.listdir(folder_path):\n",
    "        # 폴더 내 파일이 실제 파일인지 확인하고 '.ipynb_checkpoints' 폴더를 건너뛴다.\n",
    "        full_path = os.path.join(folder_path, image_filename)\n",
    "        if os.path.isfile(full_path) and '.ipynb_checkpoints' not in full_path:\n",
    "            image_paths.append(full_path)\n",
    "            image_labels.append(label_map[label_folder])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal: 534\n",
      "Aom: 119\n",
      "Chornic: 63\n",
      "Earwax: 140\n"
     ]
    }
   ],
   "source": [
    "label_0_count = image_labels.count(0)\n",
    "label_1_count = image_labels.count(1)\n",
    "label_2_count = image_labels.count(2)\n",
    "label_3_count = image_labels.count(3)\n",
    "\n",
    "print('Normal:', label_0_count)\n",
    "print('Aom:', label_1_count)\n",
    "print('Chornic:', label_2_count)\n",
    "print('Earwax:', label_3_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# 이미지 경로와 라벨을 Numpy 배열로 변환\n",
    "image_paths = np.array(image_paths)\n",
    "image_labels = np.array(image_labels)\n",
    "\n",
    "# 데이터프레임으로 변환\n",
    "data = pd.DataFrame({'image_path': image_paths, 'label': image_labels})\n",
    "\n",
    "# 클래스별로 지정된 수의 샘플을 추출하여 테스트 세트로 사용(4:20 #other)\n",
    "test_counts = {\n",
    "    0: 106,  # Normal\n",
    "    1: 24,   # AOM\n",
    "    2: 13,   # CSOM\n",
    "    3: 28   # Earwax\n",
    "}\n",
    "\n",
    "test_data_list = []\n",
    "\n",
    "for label, count in test_counts.items():\n",
    "    class_data = data[data['label'] == label]\n",
    "    if len(class_data) < count:\n",
    "        raise ValueError(f\"Not enough samples for class {label}. Needed {count}, but only {len(class_data)} available.\")\n",
    "    test_data_list.append(class_data.sample(n=count, random_state=42))\n",
    "\n",
    "test_data = pd.concat(test_data_list)\n",
    "\n",
    "# 나머지 데이터를 훈련 세트로 사용\n",
    "train_data = data.drop(test_data.index)\n",
    "\n",
    "# 훈련 세트와 테스트 세트로 나누기\n",
    "x_train = train_data['image_path'].values\n",
    "y_train = train_data['label'].values\n",
    "x_test = test_data['image_path'].values\n",
    "y_test = test_data['label'].values\n",
    "\n",
    "# # train 8: validation 2 분할\n",
    "# x_train, x_test, y_train, y_test = train_test_split(\n",
    "#     image_paths, image_labels, stratify=image_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Train set:\", len(x_train))\n",
    "# print(\"test set:\", len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 685\n",
      "Test set size: 171\n",
      "Test set class distribution:\n",
      " label\n",
      "0    106\n",
      "3     28\n",
      "1     24\n",
      "2     13\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(\"Training set size:\", len(x_train))\n",
    "print(\"Test set size:\", len(x_test))\n",
    "print(\"Test set class distribution:\\n\", test_data['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras을 사용한 데이터 증강  \n",
    "224 by 224  \n",
    "Normal 클래스가 가장 많은 샘플 수를 가지고 있으므로, 이를 기준으로 AOM, CSOM, Earwax 클래스을 각각 3배, 7배, 3배 증강  \n",
    "증강을 하면 train set에 있는 total sample 수는 normal 428, Aom 380, Csom 400, Earwax 448 으로 각 클래스가 비슷해짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 레이블을 문자열로 변환\n",
    "train_data['label'] = train_data['label'].astype(str)\n",
    "test_data['label'] = test_data['label'].astype(str)\n",
    "\n",
    "# 데이터 증강 파라미터 정의\n",
    "data_gen_args = dict(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.7, 1.3],  # ±30% 밝기 조절\n",
    "    width_shift_range=0.2,  # 좌우 이동 범위 20%\n",
    "    height_shift_range=0.2,  # 상하 이동 범위 20%\n",
    "    zoom_range=0.2,  # ±20% 확대/축소\n",
    "    rotation_range=20  # ±20도 회전\n",
    ")\n",
    "\n",
    "# 데이터 증강 제네레이터 생성\n",
    "datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "# 증강된 샘플 수를 지정(4:4 #Other)\n",
    "augment_counts = {\n",
    "    1: 3,  # AOM\n",
    "    2: 7,  # CSOM\n",
    "    3: 3  # Earwax\n",
    "}\n",
    "\n",
    "# 증강된 데이터를 저장할 리스트\n",
    "augmented_data = []\n",
    "\n",
    "for label, count in augment_counts.items():\n",
    "    class_data = train_data[train_data['label'] == str(label)]\n",
    "    for i in range(count):\n",
    "        for index, row in class_data.iterrows():\n",
    "            img = tf.keras.preprocessing.image.load_img(row['image_path'], target_size=(224, 224))\n",
    "            img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "            augmented_iter = datagen.flow(img_array, batch_size=1)\n",
    "            augmented_img = next(augmented_iter)[0].astype(np.uint8)\n",
    "            augmented_data.append({'image_path': row['image_path'], 'label': row['label']})\n",
    "            \n",
    "# 원본 데이터와 증강 데이터를 결합\n",
    "augmented_df = pd.DataFrame(augmented_data)\n",
    "train_data = pd.concat([train_data, augmented_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "3    448\n",
      "0    428\n",
      "2    400\n",
      "1    380\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "2    350\n",
      "3    336\n",
      "1    285\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "print(train_data['label'].value_counts())\n",
    "print(augmented_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Found 1656 validated image filenames belonging to 4 classes.\n",
      "Found 171 validated image filenames belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 10:26:16.780949: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorDataset/_1\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\017TensorDataset:0\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 46 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 46 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 10:26:37.252033: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8907\n",
      "2024-06-05 10:26:37.507138: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8907\n",
      "2024-06-05 10:26:37.935132: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-06-05 10:26:37.938789: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-06-05 10:26:38.396840: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-06-05 10:26:51.267746: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fa528003a90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-05 10:26:51.267787: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Quadro RTX 5000, Compute Capability 7.5\n",
      "2024-06-05 10:26:51.267802: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): Quadro RTX 5000, Compute Capability 7.5\n",
      "2024-06-05 10:26:51.267807: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): Quadro RTX 5000, Compute Capability 7.5\n",
      "2024-06-05 10:26:51.267811: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): Quadro RTX 5000, Compute Capability 7.5\n",
      "2024-06-05 10:26:51.286903: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-05 10:26:51.439544: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-06-05 10:26:51.439730: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-06-05 10:26:51.449235: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-06-05 10:26:51.452816: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-06-05 10:26:51.473780: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-06-05 10:26:51.502428: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-06-05 10:26:51.503003: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-06-05 10:26:51.508283: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-06-05 10:26:51.650433: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-06-05 10:26:51.907867: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-06-05 10:26:52.099342: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "828/828 [==============================] - ETA: 0s - loss: 1.4030 - accuracy: 0.2373"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 10:30:53.829661: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorDataset/_1\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\020TensorDataset:40\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "828/828 [==============================] - 285s 300ms/step - loss: 1.4030 - accuracy: 0.2373 - val_loss: 1.4008 - val_accuracy: 0.1462\n",
      "Epoch 2/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3968 - accuracy: 0.2591 - val_loss: 1.4227 - val_accuracy: 0.1520\n",
      "Epoch 3/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3931 - accuracy: 0.2627 - val_loss: 1.4118 - val_accuracy: 0.1228\n",
      "Epoch 4/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3943 - accuracy: 0.2566 - val_loss: 1.3746 - val_accuracy: 0.2339\n",
      "Epoch 5/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3865 - accuracy: 0.2609 - val_loss: 1.4169 - val_accuracy: 0.1637\n",
      "Epoch 6/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3848 - accuracy: 0.2627 - val_loss: 1.3167 - val_accuracy: 0.4327\n",
      "Epoch 7/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3830 - accuracy: 0.2736 - val_loss: 1.4528 - val_accuracy: 0.0819\n",
      "Epoch 8/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3819 - accuracy: 0.2941 - val_loss: 1.4056 - val_accuracy: 0.1579\n",
      "Epoch 9/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3832 - accuracy: 0.2705 - val_loss: 1.4039 - val_accuracy: 0.1345\n",
      "Epoch 10/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3832 - accuracy: 0.2681 - val_loss: 1.3819 - val_accuracy: 0.1871\n",
      "Epoch 11/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3792 - accuracy: 0.2784 - val_loss: 1.4339 - val_accuracy: 0.1053\n",
      "Epoch 12/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3766 - accuracy: 0.2935 - val_loss: 1.4344 - val_accuracy: 0.1053\n",
      "Epoch 13/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3807 - accuracy: 0.2766 - val_loss: 1.3279 - val_accuracy: 0.3684\n",
      "Epoch 14/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3794 - accuracy: 0.2699 - val_loss: 1.3393 - val_accuracy: 0.2749\n",
      "Epoch 15/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3817 - accuracy: 0.2723 - val_loss: 1.3708 - val_accuracy: 0.1813\n",
      "Epoch 16/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3778 - accuracy: 0.2814 - val_loss: 1.4117 - val_accuracy: 0.1228\n",
      "Epoch 17/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3777 - accuracy: 0.2832 - val_loss: 1.3734 - val_accuracy: 0.1462\n",
      "Epoch 18/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3761 - accuracy: 0.2772 - val_loss: 1.3710 - val_accuracy: 0.2222\n",
      "Epoch 19/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3741 - accuracy: 0.2911 - val_loss: 1.3553 - val_accuracy: 0.2456\n",
      "Epoch 20/100\n",
      "828/828 [==============================] - 247s 298ms/step - loss: 1.3754 - accuracy: 0.2663 - val_loss: 1.3510 - val_accuracy: 0.1988\n",
      "Epoch 21/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3760 - accuracy: 0.2929 - val_loss: 1.3431 - val_accuracy: 0.2807\n",
      "Epoch 22/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3729 - accuracy: 0.2971 - val_loss: 1.3862 - val_accuracy: 0.1754\n",
      "Epoch 23/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3737 - accuracy: 0.2959 - val_loss: 1.3331 - val_accuracy: 0.2924\n",
      "Epoch 24/100\n",
      "828/828 [==============================] - 247s 298ms/step - loss: 1.3706 - accuracy: 0.3025 - val_loss: 1.3931 - val_accuracy: 0.2164\n",
      "Epoch 25/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3743 - accuracy: 0.2935 - val_loss: 1.3224 - val_accuracy: 0.3801\n",
      "Epoch 26/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3693 - accuracy: 0.3043 - val_loss: 1.3060 - val_accuracy: 0.3918\n",
      "Epoch 27/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3692 - accuracy: 0.3013 - val_loss: 1.3414 - val_accuracy: 0.3041\n",
      "Epoch 28/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3668 - accuracy: 0.3092 - val_loss: 1.2781 - val_accuracy: 0.4737\n",
      "Epoch 29/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3674 - accuracy: 0.3128 - val_loss: 1.3375 - val_accuracy: 0.3216\n",
      "Epoch 30/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3698 - accuracy: 0.3110 - val_loss: 1.2993 - val_accuracy: 0.4152\n",
      "Epoch 31/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3674 - accuracy: 0.3013 - val_loss: 1.2893 - val_accuracy: 0.3860\n",
      "Epoch 32/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3654 - accuracy: 0.3080 - val_loss: 1.3173 - val_accuracy: 0.3918\n",
      "Epoch 33/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3652 - accuracy: 0.3110 - val_loss: 1.3388 - val_accuracy: 0.3450\n",
      "Epoch 34/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3626 - accuracy: 0.3182 - val_loss: 1.3251 - val_accuracy: 0.3450\n",
      "Epoch 35/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3604 - accuracy: 0.3116 - val_loss: 1.3303 - val_accuracy: 0.3626\n",
      "Epoch 36/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3618 - accuracy: 0.3243 - val_loss: 1.2961 - val_accuracy: 0.4327\n",
      "Epoch 37/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3616 - accuracy: 0.3200 - val_loss: 1.2848 - val_accuracy: 0.4561\n",
      "Epoch 38/100\n",
      "828/828 [==============================] - 247s 298ms/step - loss: 1.3611 - accuracy: 0.3225 - val_loss: 1.3422 - val_accuracy: 0.3450\n",
      "Epoch 39/100\n",
      "828/828 [==============================] - 246s 298ms/step - loss: 1.3648 - accuracy: 0.3194 - val_loss: 1.3052 - val_accuracy: 0.4269\n",
      "Epoch 40/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3565 - accuracy: 0.3442 - val_loss: 1.3590 - val_accuracy: 0.3333\n",
      "Epoch 41/100\n",
      "828/828 [==============================] - 246s 298ms/step - loss: 1.3562 - accuracy: 0.3309 - val_loss: 1.2968 - val_accuracy: 0.4269\n",
      "Epoch 42/100\n",
      "828/828 [==============================] - 246s 298ms/step - loss: 1.3566 - accuracy: 0.3207 - val_loss: 1.3105 - val_accuracy: 0.4211\n",
      "Epoch 43/100\n",
      "828/828 [==============================] - 247s 298ms/step - loss: 1.3548 - accuracy: 0.3460 - val_loss: 1.2811 - val_accuracy: 0.4620\n",
      "Epoch 44/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3528 - accuracy: 0.3406 - val_loss: 1.2859 - val_accuracy: 0.4561\n",
      "Epoch 45/100\n",
      "828/828 [==============================] - 246s 298ms/step - loss: 1.3538 - accuracy: 0.3430 - val_loss: 1.3041 - val_accuracy: 0.3801\n",
      "Epoch 46/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3556 - accuracy: 0.3394 - val_loss: 1.3006 - val_accuracy: 0.4152\n",
      "Epoch 47/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3507 - accuracy: 0.3315 - val_loss: 1.3042 - val_accuracy: 0.4269\n",
      "Epoch 48/100\n",
      "828/828 [==============================] - 246s 298ms/step - loss: 1.3504 - accuracy: 0.3514 - val_loss: 1.2614 - val_accuracy: 0.4503\n",
      "Epoch 49/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3510 - accuracy: 0.3376 - val_loss: 1.2909 - val_accuracy: 0.4152\n",
      "Epoch 50/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3455 - accuracy: 0.3527 - val_loss: 1.3048 - val_accuracy: 0.4561\n",
      "Epoch 51/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3451 - accuracy: 0.3641 - val_loss: 1.2711 - val_accuracy: 0.4737\n",
      "Epoch 52/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3482 - accuracy: 0.3472 - val_loss: 1.2627 - val_accuracy: 0.4737\n",
      "Epoch 53/100\n",
      "828/828 [==============================] - 246s 297ms/step - loss: 1.3476 - accuracy: 0.3563 - val_loss: 1.2477 - val_accuracy: 0.4678\n",
      "Epoch 54/100\n",
      "795/828 [===========================>..] - ETA: 9s - loss: 1.3397 - accuracy: 0.3409"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 136\u001b[0m\n\u001b[1;32m    133\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m, beta_1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, beta_2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.999\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/tensor/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/micromamba/envs/tensor/lib/python3.9/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/micromamba/envs/tensor/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/micromamba/envs/tensor/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/micromamba/envs/tensor/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/micromamba/envs/tensor/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/tensor/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/micromamba/envs/tensor/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/micromamba/envs/tensor/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, GlobalAveragePooling2D, Dense, Dropout, BatchNormalization, Activation, Input, LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# logical_gpus = tf.config.experimental.list_logical_devices ('GPU')\n",
    "# strategy = tf.distribute.MirroredStrategy(logical_gpus)\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    # 데이터 증강 설정\n",
    "    data_gen_args = dict(\n",
    "        rescale=1./255,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        brightness_range=[0.7, 1.3],\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.2\n",
    "    )\n",
    "\n",
    "    # 데이터 증강 생성기\n",
    "    train_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # 데이터 증강 적용 (train_data는 데이터프레임 형태라고 가정)\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_data,\n",
    "        x_col='image_path',\n",
    "        y_col='label',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=2,  # 배치 크기를 줄임\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    val_generator = test_datagen.flow_from_dataframe(\n",
    "        dataframe=test_data,\n",
    "        x_col='image_path',\n",
    "        y_col='label',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=2,  # 배치 크기를 줄임\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    # Convolutional Block 정의\n",
    "    def conv_block(x, filters):\n",
    "        x = Conv2D(filters, (3, 3), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        return x\n",
    "\n",
    "    # Residual Block 정의\n",
    "    def residual_block(x, filters):\n",
    "        shortcut = x\n",
    "        x = Conv2D(filters, (3, 3), padding='same', strides=(1, 1))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Conv2D(filters, (3, 3), padding='same', strides=(1, 1))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.keras.layers.add([x, shortcut])\n",
    "        x = LeakyReLU()(x)\n",
    "        return x\n",
    "\n",
    "    # Channel Attention Module 정의\n",
    "    def channel_attention(x):\n",
    "        avg_pool = GlobalAveragePooling2D()(x)\n",
    "        max_pool = GlobalAveragePooling2D()(x)\n",
    "        dense_avg = Dense(x.shape[-1], activation='relu', kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')(avg_pool)\n",
    "        dense_max = Dense(x.shape[-1], activation='relu', kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')(max_pool)\n",
    "        combined = tf.keras.layers.add([dense_avg, dense_max])\n",
    "        channel_attention = Activation('sigmoid')(combined)\n",
    "        return tf.keras.layers.multiply([x, channel_attention])\n",
    "\n",
    "    # Spatial Attention Module 정의\n",
    "    def spatial_attention(x):\n",
    "        avg_pool = tf.reduce_mean(x, axis=-1, keepdims=True)\n",
    "        max_pool = tf.reduce_max(x, axis=-1, keepdims=True)\n",
    "        combined = Concatenate(axis=-1)([avg_pool, max_pool])\n",
    "        spatial_attention = Conv2D(1, (7, 7), padding='same', activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(combined)\n",
    "        return tf.keras.layers.multiply([x, spatial_attention])\n",
    "\n",
    "    # CBAM Block 정의\n",
    "    def cbam_block(x):\n",
    "        x = channel_attention(x)\n",
    "        x = spatial_attention(x)\n",
    "        return x\n",
    "\n",
    "    # Stage 1 정의\n",
    "    def stage1(input_tensor):\n",
    "        x = conv_block(input_tensor, 32)\n",
    "        x = conv_block(x, 32)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "        x = UpSampling2D((4, 4), interpolation='bilinear')(x)  \n",
    "        return x\n",
    "\n",
    "    # Stage 2 정의\n",
    "    def stage2(input_tensor):\n",
    "        x = conv_block(input_tensor, 64)\n",
    "        x = cbam_block(x)\n",
    "        x = residual_block(x, 64)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "        x = UpSampling2D((4, 4), interpolation='bilinear')(x)  \n",
    "        return x\n",
    "\n",
    "    # Stage 3 정의\n",
    "    def stage3(input_tensor):\n",
    "        x = conv_block(input_tensor, 128)\n",
    "        x = cbam_block(x)\n",
    "        x = residual_block(x, 128)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "        x = UpSampling2D((4, 4), interpolation='bilinear')(x)  \n",
    "        return x\n",
    "\n",
    "    # 모델 구성\n",
    "    input_tensor = Input(shape=(224, 224, 3))\n",
    "\n",
    "    stage1_output = stage1(input_tensor)\n",
    "    stage2_output = stage2(stage1_output)\n",
    "    stage3_output = stage3(stage2_output)\n",
    "\n",
    "    #concatenated = Concatenate()([stage1_output, stage2_output, stage3_output])\n",
    "\n",
    "    x = GlobalAveragePooling2D()(stage3_output)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    output = Dense(4, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=output)\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 모델 학습\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=100,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=len(val_generator)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 학습 결과 시각화\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(100)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 Summary:\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 224, 224, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 224, 224, 32)     128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 224, 224, 32)      0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 224, 224, 32)      9248      \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 224, 224, 32)     128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 224, 224, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 112, 112, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " up_sampling2d_3 (UpSampling  (None, 224, 224, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,400\n",
      "Trainable params: 10,272\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Stage 1 summary\n",
    "stage1_output = stage1(input_tensor)\n",
    "stage1_model = Model(inputs=input_tensor, outputs=stage1_output)\n",
    "print(\"Stage 1 Summary:\")\n",
    "stage1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stage 2 Summary:\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 224, 224, 32  896         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 224, 224, 32  128        ['conv2d_10[0][0]']              \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 224, 224, 32  0           ['batch_normalization_8[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 224, 224, 32  9248        ['activation_6[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 224, 224, 32  128        ['conv2d_11[0][0]']              \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 224, 224, 32  0           ['batch_normalization_9[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 112, 112, 32  0          ['activation_7[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 224, 224, 32  0          ['max_pooling2d_3[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 224, 224, 64  18496       ['up_sampling2d_3[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 224, 224, 64  256        ['conv2d_12[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 224, 224, 64  0           ['batch_normalization_10[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_5 (Gl  (None, 64)          0           ['activation_8[0][0]']           \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling2d_6 (Gl  (None, 64)          0           ['activation_8[0][0]']           \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 64)           4160        ['global_average_pooling2d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 64)           4160        ['global_average_pooling2d_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 64)           0           ['dense_6[0][0]',                \n",
      "                                                                  'dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 64)           0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)          (None, 224, 224, 64  0           ['activation_8[0][0]',           \n",
      "                                )                                 'activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_2 (TFOpLam  (None, 224, 224, 1)  0          ['multiply_4[0][0]']             \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_2 (TFOpLamb  (None, 224, 224, 1)  0          ['multiply_4[0][0]']             \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 224, 224, 2)  0           ['tf.math.reduce_mean_2[0][0]',  \n",
      "                                                                  'tf.math.reduce_max_2[0][0]']   \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 224, 224, 1)  98          ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_5 (Multiply)          (None, 224, 224, 64  0           ['multiply_4[0][0]',             \n",
      "                                )                                 'conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 224, 224, 64  36928       ['multiply_5[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 224, 224, 64  256        ['conv2d_14[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 224, 224, 64  0           ['batch_normalization_11[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 224, 224, 64  36928       ['leaky_re_lu_4[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 224, 224, 64  256        ['conv2d_15[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 224, 224, 64  0           ['batch_normalization_12[0][0]', \n",
      "                                )                                 'multiply_5[0][0]']             \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 224, 224, 64  0           ['add_5[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 112, 112, 64  0          ['leaky_re_lu_5[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 64  0          ['max_pooling2d_4[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 111,938\n",
      "Trainable params: 111,426\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Stage 2 summary\n",
    "stage2_output = stage2(stage1_output)\n",
    "stage2_model = Model(inputs=input_tensor, outputs=stage2_output)\n",
    "print(\"\\nStage 2 Summary:\")\n",
    "stage2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stage 3 Summary:\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 224, 224, 32  896         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 224, 224, 32  128        ['conv2d_10[0][0]']              \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 224, 224, 32  0           ['batch_normalization_8[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 224, 224, 32  9248        ['activation_6[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 224, 224, 32  128        ['conv2d_11[0][0]']              \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 224, 224, 32  0           ['batch_normalization_9[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 112, 112, 32  0          ['activation_7[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 224, 224, 32  0          ['max_pooling2d_3[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 224, 224, 64  18496       ['up_sampling2d_3[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 224, 224, 64  256        ['conv2d_12[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 224, 224, 64  0           ['batch_normalization_10[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_5 (Gl  (None, 64)          0           ['activation_8[0][0]']           \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling2d_6 (Gl  (None, 64)          0           ['activation_8[0][0]']           \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 64)           4160        ['global_average_pooling2d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 64)           4160        ['global_average_pooling2d_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 64)           0           ['dense_6[0][0]',                \n",
      "                                                                  'dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 64)           0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)          (None, 224, 224, 64  0           ['activation_8[0][0]',           \n",
      "                                )                                 'activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_2 (TFOpLam  (None, 224, 224, 1)  0          ['multiply_4[0][0]']             \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_2 (TFOpLamb  (None, 224, 224, 1)  0          ['multiply_4[0][0]']             \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 224, 224, 2)  0           ['tf.math.reduce_mean_2[0][0]',  \n",
      "                                                                  'tf.math.reduce_max_2[0][0]']   \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 224, 224, 1)  98          ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_5 (Multiply)          (None, 224, 224, 64  0           ['multiply_4[0][0]',             \n",
      "                                )                                 'conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 224, 224, 64  36928       ['multiply_5[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 224, 224, 64  256        ['conv2d_14[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 224, 224, 64  0           ['batch_normalization_11[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 224, 224, 64  36928       ['leaky_re_lu_4[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 224, 224, 64  256        ['conv2d_15[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 224, 224, 64  0           ['batch_normalization_12[0][0]', \n",
      "                                )                                 'multiply_5[0][0]']             \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 224, 224, 64  0           ['add_5[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 112, 112, 64  0          ['leaky_re_lu_5[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 64  0          ['max_pooling2d_4[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 224, 224, 12  73856       ['up_sampling2d_4[0][0]']        \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 224, 224, 12  512        ['conv2d_16[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 224, 224, 12  0           ['batch_normalization_13[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " global_average_pooling2d_7 (Gl  (None, 128)         0           ['activation_10[0][0]']          \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling2d_8 (Gl  (None, 128)         0           ['activation_10[0][0]']          \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 128)          16512       ['global_average_pooling2d_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 128)          16512       ['global_average_pooling2d_8[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 128)          0           ['dense_8[0][0]',                \n",
      "                                                                  'dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 128)          0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " multiply_6 (Multiply)          (None, 224, 224, 12  0           ['activation_10[0][0]',          \n",
      "                                8)                                'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_3 (TFOpLam  (None, 224, 224, 1)  0          ['multiply_6[0][0]']             \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_3 (TFOpLamb  (None, 224, 224, 1)  0          ['multiply_6[0][0]']             \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 224, 224, 2)  0           ['tf.math.reduce_mean_3[0][0]',  \n",
      "                                                                  'tf.math.reduce_max_3[0][0]']   \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 224, 224, 1)  98          ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_7 (Multiply)          (None, 224, 224, 12  0           ['multiply_6[0][0]',             \n",
      "                                8)                                'conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 224, 224, 12  147584      ['multiply_7[0][0]']             \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 224, 224, 12  512        ['conv2d_18[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 224, 224, 12  0           ['batch_normalization_14[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 224, 224, 12  147584      ['leaky_re_lu_6[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 224, 224, 12  512        ['conv2d_19[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 224, 224, 12  0           ['batch_normalization_15[0][0]', \n",
      "                                8)                                'multiply_7[0][0]']             \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 224, 224, 12  0           ['add_7[0][0]']                  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 112, 112, 12  0          ['leaky_re_lu_7[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 12  0          ['max_pooling2d_5[0][0]']        \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 515,620\n",
      "Trainable params: 514,340\n",
      "Non-trainable params: 1,280\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Stage 3 summary\n",
    "stage3_output = stage3(stage2_output)\n",
    "stage3_model = Model(inputs=input_tensor, outputs=stage3_output)\n",
    "print(\"\\nStage 3 Summary:\")\n",
    "stage3_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
