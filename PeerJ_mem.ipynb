{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gpu 메모리 부족 현상이 발생해서 이에 대한 새로운 접근\n",
    "mini_batch size: 24->12  \n",
    "upsampling: (4,4) -> (2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 09:14:16.598047: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-06 09:14:16.721778: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPUs will likely run quickly with dtype policy mixed_float16 as they all have compute capability of at least 7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "# mixed precision 설정\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "# GPU 설정\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  4\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기 및 클래스 지정과 분할  \n",
    "The numbers of samples in each class for the test set are distributed as 106 (normal), 24 (AOM), 13 (CSOM), 28 (Earwax), and 20 (Other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 데이터셋의 루트 디렉토리\n",
    "dataset_directory = '/home/jeonk636/ear_classification/eardrumDs'\n",
    "\n",
    "# 클래스 이름 및 라벨을 매핑하기 위한 딕셔너리 생성\n",
    "# normal:0, Aom:1, Chornic:2, Earwax:3, Others:4\n",
    "label_map = {\n",
    "    'Aom': 1,\n",
    "    'Chornic': 2,\n",
    "    'Earwax': 3,\n",
    "    'Normal': 0,\n",
    "}\n",
    "\n",
    "# 이미지 파일 경로 및 라벨을 저장할 리스트\n",
    "image_paths = []\n",
    "image_labels = []\n",
    "\n",
    "exclude_folders = {'OtitExterna', 'tympanoskleros', 'Earventulation', 'Foreign', 'PseduoMembran'}\n",
    "\n",
    "# 각 폴더에 대해 이미지 파일 경로 및 해당 라벨을 리스트에 추가\n",
    "for label_folder in os.listdir(dataset_directory):\n",
    "    if label_folder in exclude_folders:  # 이 폴더는 건너뛴다.\n",
    "        continue\n",
    "    folder_path = os.path.join(dataset_directory, label_folder)\n",
    "    \n",
    "    for image_filename in os.listdir(folder_path):\n",
    "        # 폴더 내 파일이 실제 파일인지 확인하고 '.ipynb_checkpoints' 폴더를 건너뛴다.\n",
    "        full_path = os.path.join(folder_path, image_filename)\n",
    "        if os.path.isfile(full_path) and '.ipynb_checkpoints' not in full_path:\n",
    "            image_paths.append(full_path)\n",
    "            image_labels.append(label_map[label_folder])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal: 534\n",
      "Aom: 119\n",
      "Chornic: 63\n",
      "Earwax: 140\n"
     ]
    }
   ],
   "source": [
    "label_0_count = image_labels.count(0)\n",
    "label_1_count = image_labels.count(1)\n",
    "label_2_count = image_labels.count(2)\n",
    "label_3_count = image_labels.count(3)\n",
    "\n",
    "print('Normal:', label_0_count)\n",
    "print('Aom:', label_1_count)\n",
    "print('Chornic:', label_2_count)\n",
    "print('Earwax:', label_3_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# 이미지 경로와 라벨을 Numpy 배열로 변환\n",
    "image_paths = np.array(image_paths)\n",
    "image_labels = np.array(image_labels)\n",
    "\n",
    "# 데이터프레임으로 변환\n",
    "data = pd.DataFrame({'image_path': image_paths, 'label': image_labels})\n",
    "\n",
    "# 클래스별로 지정된 수의 샘플을 추출하여 테스트 세트로 사용(4:20 #other)\n",
    "test_counts = {\n",
    "    0: 106,  # Normal\n",
    "    1: 24,   # AOM\n",
    "    2: 13,   # CSOM\n",
    "    3: 28   # Earwax\n",
    "}\n",
    "\n",
    "test_data_list = []\n",
    "\n",
    "for label, count in test_counts.items():\n",
    "    class_data = data[data['label'] == label]\n",
    "    if len(class_data) < count:\n",
    "        raise ValueError(f\"Not enough samples for class {label}. Needed {count}, but only {len(class_data)} available.\")\n",
    "    test_data_list.append(class_data.sample(n=count, random_state=42))\n",
    "\n",
    "test_data = pd.concat(test_data_list)\n",
    "\n",
    "# 나머지 데이터를 훈련 세트로 사용\n",
    "train_data = data.drop(test_data.index)\n",
    "\n",
    "# 훈련 세트와 테스트 세트로 나누기\n",
    "x_train = train_data['image_path'].values\n",
    "y_train = train_data['label'].values\n",
    "x_test = test_data['image_path'].values\n",
    "y_test = test_data['label'].values\n",
    "\n",
    "# # train 8: validation 2 분할\n",
    "# x_train, x_test, y_train, y_test = train_test_split(\n",
    "#     image_paths, image_labels, stratify=image_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Train set:\", len(x_train))\n",
    "# print(\"test set:\", len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 685\n",
      "Test set size: 171\n",
      "Test set class distribution:\n",
      " label\n",
      "0    106\n",
      "3     28\n",
      "1     24\n",
      "2     13\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(\"Training set size:\", len(x_train))\n",
    "print(\"Test set size:\", len(x_test))\n",
    "print(\"Test set class distribution:\\n\", test_data['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras을 사용한 데이터 증강  \n",
    "224 by 224  \n",
    "Normal 클래스가 가장 많은 샘플 수를 가지고 있으므로, 이를 기준으로 AOM, CSOM, Earwax 클래스을 각각 3배, 7배, 3배 증강  \n",
    "증강을 하면 train set에 있는 total sample 수는 normal 428, Aom 380, Csom 400, Earwax 448 으로 각 클래스가 비슷해짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 레이블을 문자열로 변환\n",
    "train_data['label'] = train_data['label'].astype(str)\n",
    "test_data['label'] = test_data['label'].astype(str)\n",
    "\n",
    "# 데이터 증강 파라미터 정의\n",
    "data_gen_args = dict(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.7, 1.3],  # ±30% 밝기 조절\n",
    "    width_shift_range=0.2,  # 좌우 이동 범위 20%\n",
    "    height_shift_range=0.2,  # 상하 이동 범위 20%\n",
    "    zoom_range=0.2,  # ±20% 확대/축소\n",
    "    rotation_range=20  # ±20도 회전\n",
    ")\n",
    "\n",
    "# 데이터 증강 제네레이터 생성\n",
    "datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "# 증강된 샘플 수를 지정(4:4 #Other)\n",
    "augment_counts = {\n",
    "    1: 3,  # AOM\n",
    "    2: 7,  # CSOM\n",
    "    3: 3  # Earwax\n",
    "}\n",
    "\n",
    "# 증강된 데이터를 저장할 리스트\n",
    "augmented_data = []\n",
    "\n",
    "for label, count in augment_counts.items():\n",
    "    class_data = train_data[train_data['label'] == str(label)]\n",
    "    for i in range(count):\n",
    "        for index, row in class_data.iterrows():\n",
    "            img = tf.keras.preprocessing.image.load_img(row['image_path'], target_size=(224, 224))\n",
    "            img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "            augmented_iter = datagen.flow(img_array, batch_size=1)\n",
    "            augmented_img = next(augmented_iter)[0].astype(np.uint8)\n",
    "            augmented_data.append({'image_path': row['image_path'], 'label': row['label']})\n",
    "            \n",
    "# 원본 데이터와 증강 데이터를 결합\n",
    "augmented_df = pd.DataFrame(augmented_data)\n",
    "train_data = pd.concat([train_data, augmented_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "3    448\n",
      "0    428\n",
      "2    400\n",
      "1    380\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "2    350\n",
      "3    336\n",
      "1    285\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "print(train_data['label'].value_counts())\n",
    "print(augmented_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Found 1656 validated image filenames belonging to 4 classes.\n",
      "Found 171 validated image filenames belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 09:19:04.787612: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorDataset/_1\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\020TensorDataset:40\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 46 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 46 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 09:19:36.895387: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fe4f0004ac0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-06 09:19:36.895458: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Quadro RTX 5000, Compute Capability 7.5\n",
      "2024-06-06 09:19:36.895473: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): Quadro RTX 5000, Compute Capability 7.5\n",
      "2024-06-06 09:19:36.895484: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): Quadro RTX 5000, Compute Capability 7.5\n",
      "2024-06-06 09:19:36.895494: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): Quadro RTX 5000, Compute Capability 7.5\n",
      "2024-06-06 09:19:36.907005: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-06 09:19:36.994529: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-06-06 09:19:36.994660: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-06-06 09:19:36.994722: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-06-06 09:19:37.029776: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-06-06 09:19:37.060505: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-06-06 09:19:37.135185: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-06-06 09:19:37.278155: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-06-06 09:19:37.417048: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-06-06 09:19:37.468495: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-06-06 09:19:37.600430: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-06-06 09:19:37.798544: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414/414 [==============================] - ETA: 0s - loss: 1.4033 - accuracy: 0.2609"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 09:21:39.609932: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorDataset/_1\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\020TensorDataset:80\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414/414 [==============================] - 160s 303ms/step - loss: 1.4033 - accuracy: 0.2609 - val_loss: 1.3833 - val_accuracy: 0.1930\n",
      "Epoch 2/100\n",
      "414/414 [==============================] - 123s 298ms/step - loss: 1.3953 - accuracy: 0.2687 - val_loss: 1.2788 - val_accuracy: 0.4912\n",
      "Epoch 3/100\n",
      "414/414 [==============================] - 124s 298ms/step - loss: 1.3988 - accuracy: 0.2421 - val_loss: 1.2560 - val_accuracy: 0.4854\n",
      "Epoch 4/100\n",
      "414/414 [==============================] - 124s 299ms/step - loss: 1.3857 - accuracy: 0.2766 - val_loss: 1.2349 - val_accuracy: 0.5088\n",
      "Epoch 5/100\n",
      "414/414 [==============================] - 124s 298ms/step - loss: 1.3829 - accuracy: 0.2699 - val_loss: 1.2410 - val_accuracy: 0.4795\n",
      "Epoch 6/100\n",
      "414/414 [==============================] - 124s 298ms/step - loss: 1.3826 - accuracy: 0.2886 - val_loss: 1.2639 - val_accuracy: 0.5146\n",
      "Epoch 7/100\n",
      "414/414 [==============================] - 124s 298ms/step - loss: 1.3834 - accuracy: 0.2844 - val_loss: 1.2728 - val_accuracy: 0.3918\n",
      "Epoch 8/100\n",
      "414/414 [==============================] - 124s 298ms/step - loss: 1.3763 - accuracy: 0.2965 - val_loss: 1.2565 - val_accuracy: 0.4561\n",
      "Epoch 9/100\n",
      "414/414 [==============================] - 123s 298ms/step - loss: 1.3758 - accuracy: 0.2850 - val_loss: 1.2345 - val_accuracy: 0.5497\n",
      "Epoch 10/100\n",
      "414/414 [==============================] - 124s 298ms/step - loss: 1.3792 - accuracy: 0.2911 - val_loss: 1.2328 - val_accuracy: 0.4971\n",
      "Epoch 11/100\n",
      "414/414 [==============================] - 124s 299ms/step - loss: 1.3732 - accuracy: 0.2784 - val_loss: 1.2179 - val_accuracy: 0.5322\n",
      "Epoch 12/100\n",
      "414/414 [==============================] - 124s 298ms/step - loss: 1.3742 - accuracy: 0.2886 - val_loss: 1.2469 - val_accuracy: 0.4620\n",
      "Epoch 13/100\n",
      "414/414 [==============================] - 124s 299ms/step - loss: 1.3672 - accuracy: 0.3092 - val_loss: 1.2485 - val_accuracy: 0.4795\n",
      "Epoch 14/100\n",
      "414/414 [==============================] - 124s 298ms/step - loss: 1.3705 - accuracy: 0.3068 - val_loss: 1.2370 - val_accuracy: 0.4971\n",
      "Epoch 15/100\n",
      "414/414 [==============================] - 123s 298ms/step - loss: 1.3678 - accuracy: 0.3001 - val_loss: 1.2427 - val_accuracy: 0.5614\n",
      "Epoch 16/100\n",
      "414/414 [==============================] - 124s 298ms/step - loss: 1.3660 - accuracy: 0.3170 - val_loss: 1.1979 - val_accuracy: 0.5029\n",
      "Epoch 17/100\n",
      "414/414 [==============================] - 124s 299ms/step - loss: 1.3637 - accuracy: 0.3152 - val_loss: 1.1796 - val_accuracy: 0.5322\n",
      "Epoch 18/100\n",
      "414/414 [==============================] - 124s 299ms/step - loss: 1.3609 - accuracy: 0.3261 - val_loss: 1.2050 - val_accuracy: 0.4912\n",
      "Epoch 19/100\n",
      "414/414 [==============================] - 124s 299ms/step - loss: 1.3587 - accuracy: 0.3249 - val_loss: 1.1989 - val_accuracy: 0.5439\n",
      "Epoch 20/100\n",
      "414/414 [==============================] - 124s 298ms/step - loss: 1.3624 - accuracy: 0.3502 - val_loss: 1.2006 - val_accuracy: 0.5322\n",
      "Epoch 21/100\n",
      "414/414 [==============================] - 124s 298ms/step - loss: 1.3609 - accuracy: 0.3255 - val_loss: 1.2067 - val_accuracy: 0.5146\n",
      "Epoch 22/100\n",
      "414/414 [==============================] - 124s 298ms/step - loss: 1.3574 - accuracy: 0.3406 - val_loss: 1.2169 - val_accuracy: 0.5088\n",
      "Epoch 23/100\n",
      "414/414 [==============================] - 123s 298ms/step - loss: 1.3537 - accuracy: 0.3376 - val_loss: 1.1960 - val_accuracy: 0.5380\n",
      "Epoch 24/100\n",
      "414/414 [==============================] - 124s 298ms/step - loss: 1.3518 - accuracy: 0.3454 - val_loss: 1.2090 - val_accuracy: 0.5439\n",
      "Epoch 25/100\n",
      "414/414 [==============================] - 124s 298ms/step - loss: 1.3552 - accuracy: 0.3394 - val_loss: 1.1765 - val_accuracy: 0.5146\n",
      "Epoch 26/100\n",
      "414/414 [==============================] - 124s 299ms/step - loss: 1.3486 - accuracy: 0.3424 - val_loss: 1.1685 - val_accuracy: 0.5146\n",
      "Epoch 27/100\n",
      "414/414 [==============================] - 124s 299ms/step - loss: 1.3463 - accuracy: 0.3394 - val_loss: 1.2226 - val_accuracy: 0.4971\n",
      "Epoch 28/100\n",
      "414/414 [==============================] - 123s 298ms/step - loss: 1.3453 - accuracy: 0.3490 - val_loss: 1.1910 - val_accuracy: 0.5556\n",
      "Epoch 29/100\n",
      "414/414 [==============================] - 123s 298ms/step - loss: 1.3449 - accuracy: 0.3424 - val_loss: 1.1797 - val_accuracy: 0.5322\n",
      "Epoch 30/100\n",
      "414/414 [==============================] - 124s 298ms/step - loss: 1.3421 - accuracy: 0.3406 - val_loss: 1.2288 - val_accuracy: 0.5146\n",
      "Epoch 31/100\n",
      "414/414 [==============================] - 123s 298ms/step - loss: 1.3387 - accuracy: 0.3635 - val_loss: 1.2038 - val_accuracy: 0.5205\n",
      "Epoch 32/100\n",
      "414/414 [==============================] - 123s 298ms/step - loss: 1.3335 - accuracy: 0.3714 - val_loss: 1.1979 - val_accuracy: 0.5029\n",
      "Epoch 33/100\n",
      "414/414 [==============================] - 124s 299ms/step - loss: 1.3370 - accuracy: 0.3684 - val_loss: 1.1885 - val_accuracy: 0.5322\n",
      "Epoch 34/100\n",
      "414/414 [==============================] - 124s 299ms/step - loss: 1.3322 - accuracy: 0.3714 - val_loss: 1.1700 - val_accuracy: 0.5673\n",
      "Epoch 35/100\n",
      "414/414 [==============================] - 124s 298ms/step - loss: 1.3325 - accuracy: 0.3750 - val_loss: 1.2272 - val_accuracy: 0.5556\n",
      "Epoch 36/100\n",
      "414/414 [==============================] - 123s 298ms/step - loss: 1.3293 - accuracy: 0.3786 - val_loss: 1.1528 - val_accuracy: 0.5673\n",
      "Epoch 37/100\n",
      "414/414 [==============================] - 124s 298ms/step - loss: 1.3274 - accuracy: 0.3822 - val_loss: 1.1584 - val_accuracy: 0.5146\n",
      "Epoch 38/100\n",
      "414/414 [==============================] - 124s 300ms/step - loss: 1.3234 - accuracy: 0.3726 - val_loss: 1.1502 - val_accuracy: 0.5380\n",
      "Epoch 39/100\n",
      "414/414 [==============================] - 124s 299ms/step - loss: 1.3230 - accuracy: 0.3714 - val_loss: 1.1672 - val_accuracy: 0.5146\n",
      "Epoch 40/100\n",
      "414/414 [==============================] - 124s 299ms/step - loss: 1.3237 - accuracy: 0.3702 - val_loss: 1.1373 - val_accuracy: 0.5439\n",
      "Epoch 41/100\n",
      "414/414 [==============================] - 124s 299ms/step - loss: 1.3224 - accuracy: 0.3780 - val_loss: 1.1440 - val_accuracy: 0.5439\n",
      "Epoch 42/100\n",
      "414/414 [==============================] - 124s 298ms/step - loss: 1.3180 - accuracy: 0.3955 - val_loss: 1.1261 - val_accuracy: 0.5380\n",
      "Epoch 43/100\n",
      "414/414 [==============================] - 124s 298ms/step - loss: 1.3127 - accuracy: 0.3955 - val_loss: 1.1702 - val_accuracy: 0.5322\n",
      "Epoch 44/100\n",
      "414/414 [==============================] - 123s 298ms/step - loss: 1.3177 - accuracy: 0.3853 - val_loss: 1.1380 - val_accuracy: 0.5263\n",
      "Epoch 45/100\n",
      "414/414 [==============================] - 123s 298ms/step - loss: 1.3147 - accuracy: 0.3992 - val_loss: 1.1748 - val_accuracy: 0.5439\n",
      "Epoch 46/100\n",
      "414/414 [==============================] - 124s 298ms/step - loss: 1.3124 - accuracy: 0.3810 - val_loss: 1.1935 - val_accuracy: 0.5497\n",
      "Epoch 47/100\n",
      "414/414 [==============================] - 123s 298ms/step - loss: 1.3096 - accuracy: 0.3913 - val_loss: 1.1567 - val_accuracy: 0.5439\n",
      "Epoch 48/100\n",
      "414/414 [==============================] - 123s 298ms/step - loss: 1.3067 - accuracy: 0.3973 - val_loss: 1.1448 - val_accuracy: 0.5263\n",
      "Epoch 49/100\n",
      "414/414 [==============================] - 123s 298ms/step - loss: 1.3066 - accuracy: 0.3859 - val_loss: 1.1081 - val_accuracy: 0.5556\n",
      "Epoch 50/100\n",
      "414/414 [==============================] - 124s 299ms/step - loss: 1.3078 - accuracy: 0.3889 - val_loss: 1.1498 - val_accuracy: 0.5497\n",
      "Epoch 51/100\n",
      "414/414 [==============================] - 124s 298ms/step - loss: 1.3055 - accuracy: 0.3943 - val_loss: 1.1347 - val_accuracy: 0.5263\n",
      "Epoch 52/100\n",
      "414/414 [==============================] - 124s 298ms/step - loss: 1.3108 - accuracy: 0.3786 - val_loss: 1.1200 - val_accuracy: 0.5088\n",
      "Epoch 53/100\n",
      "414/414 [==============================] - 123s 298ms/step - loss: 1.3028 - accuracy: 0.3859 - val_loss: 1.1446 - val_accuracy: 0.5380\n",
      "Epoch 54/100\n",
      "414/414 [==============================] - 123s 298ms/step - loss: 1.3085 - accuracy: 0.3967 - val_loss: 1.1179 - val_accuracy: 0.5497\n",
      "Epoch 55/100\n",
      "414/414 [==============================] - 124s 299ms/step - loss: 1.3028 - accuracy: 0.3895 - val_loss: 1.1330 - val_accuracy: 0.5380\n",
      "Epoch 56/100\n",
      "414/414 [==============================] - 123s 298ms/step - loss: 1.2986 - accuracy: 0.3949 - val_loss: 1.1498 - val_accuracy: 0.5439\n",
      "Epoch 57/100\n",
      "414/414 [==============================] - 123s 298ms/step - loss: 1.2991 - accuracy: 0.4058 - val_loss: 1.1378 - val_accuracy: 0.5380\n",
      "Epoch 58/100\n",
      "414/414 [==============================] - 124s 298ms/step - loss: 1.2991 - accuracy: 0.3877 - val_loss: 1.1533 - val_accuracy: 0.5146\n",
      "Epoch 59/100\n",
      "414/414 [==============================] - 124s 298ms/step - loss: 1.2922 - accuracy: 0.3955 - val_loss: 1.1620 - val_accuracy: 0.5380\n",
      "Epoch 60/100\n",
      "414/414 [==============================] - 124s 299ms/step - loss: 1.2938 - accuracy: 0.4070 - val_loss: 1.1203 - val_accuracy: 0.5556\n",
      "Epoch 61/100\n",
      "414/414 [==============================] - 124s 298ms/step - loss: 1.3009 - accuracy: 0.3943 - val_loss: 1.1356 - val_accuracy: 0.5556\n",
      "Epoch 62/100\n",
      "414/414 [==============================] - 124s 300ms/step - loss: 1.2994 - accuracy: 0.4004 - val_loss: 1.1714 - val_accuracy: 0.5497\n",
      "Epoch 63/100\n",
      "414/414 [==============================] - 124s 299ms/step - loss: 1.2938 - accuracy: 0.3895 - val_loss: 1.1437 - val_accuracy: 0.5497\n",
      "Epoch 64/100\n",
      "414/414 [==============================] - 124s 299ms/step - loss: 1.2944 - accuracy: 0.3798 - val_loss: 1.1426 - val_accuracy: 0.5556\n",
      "Epoch 65/100\n",
      "414/414 [==============================] - 124s 299ms/step - loss: 1.2927 - accuracy: 0.3925 - val_loss: 1.2295 - val_accuracy: 0.5205\n",
      "Epoch 66/100\n",
      "414/414 [==============================] - 124s 299ms/step - loss: 1.2924 - accuracy: 0.4118 - val_loss: 1.1394 - val_accuracy: 0.5205\n",
      "Epoch 67/100\n",
      "414/414 [==============================] - 124s 299ms/step - loss: 1.2948 - accuracy: 0.4040 - val_loss: 1.1756 - val_accuracy: 0.5556\n",
      "Epoch 68/100\n",
      "414/414 [==============================] - 124s 299ms/step - loss: 1.2852 - accuracy: 0.4136 - val_loss: 1.1388 - val_accuracy: 0.5029\n",
      "Epoch 69/100\n",
      "414/414 [==============================] - 124s 298ms/step - loss: 1.2869 - accuracy: 0.4215 - val_loss: 1.1434 - val_accuracy: 0.5556\n",
      "Epoch 70/100\n",
      "414/414 [==============================] - 124s 298ms/step - loss: 1.2857 - accuracy: 0.4070 - val_loss: 1.1528 - val_accuracy: 0.5263\n",
      "Epoch 71/100\n",
      "414/414 [==============================] - 124s 299ms/step - loss: 1.2855 - accuracy: 0.3992 - val_loss: 1.1578 - val_accuracy: 0.5497\n",
      "Epoch 72/100\n",
      "414/414 [==============================] - 123s 298ms/step - loss: 1.2888 - accuracy: 0.3973 - val_loss: 1.1683 - val_accuracy: 0.5497\n",
      "Epoch 73/100\n",
      "414/414 [==============================] - 123s 298ms/step - loss: 1.2843 - accuracy: 0.4149 - val_loss: 1.1843 - val_accuracy: 0.5614\n",
      "Epoch 74/100\n",
      "414/414 [==============================] - 123s 298ms/step - loss: 1.2847 - accuracy: 0.4167 - val_loss: 1.1728 - val_accuracy: 0.5263\n",
      "Epoch 75/100\n",
      "414/414 [==============================] - 124s 298ms/step - loss: 1.2857 - accuracy: 0.4112 - val_loss: 1.1559 - val_accuracy: 0.5322\n",
      "Epoch 76/100\n",
      "414/414 [==============================] - 123s 298ms/step - loss: 1.2818 - accuracy: 0.4100 - val_loss: 1.1249 - val_accuracy: 0.5497\n",
      "Epoch 77/100\n",
      "414/414 [==============================] - 124s 298ms/step - loss: 1.2883 - accuracy: 0.4034 - val_loss: 1.1705 - val_accuracy: 0.5146\n",
      "Epoch 78/100\n",
      "414/414 [==============================] - 124s 299ms/step - loss: 1.2820 - accuracy: 0.4094 - val_loss: 1.1549 - val_accuracy: 0.5556\n",
      "Epoch 79/100\n",
      "267/414 [==================>...........] - ETA: 42s - loss: 1.3003 - accuracy: 0.3652"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 136\u001b[0m\n\u001b[1;32m    133\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m, beta_1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, beta_2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.999\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/tensor/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/micromamba/envs/tensor/lib/python3.9/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/micromamba/envs/tensor/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/micromamba/envs/tensor/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/micromamba/envs/tensor/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/micromamba/envs/tensor/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/tensor/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/micromamba/envs/tensor/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/micromamba/envs/tensor/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, GlobalAveragePooling2D, Dense, Dropout, BatchNormalization, Activation, Input, LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# logical_gpus = tf.config.experimental.list_logical_devices ('GPU')\n",
    "# strategy = tf.distribute.MirroredStrategy(logical_gpus)\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    # 데이터 증강 설정\n",
    "    data_gen_args = dict(\n",
    "        rescale=1./255,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        brightness_range=[0.7, 1.3],\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.2\n",
    "    )\n",
    "\n",
    "    # 데이터 증강 생성기\n",
    "    train_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # 데이터 증강 적용 (train_data는 데이터프레임 형태라고 가정)\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_data,\n",
    "        x_col='image_path',\n",
    "        y_col='label',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=4,  # 배치 크기를 줄임\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    val_generator = test_datagen.flow_from_dataframe(\n",
    "        dataframe=test_data,\n",
    "        x_col='image_path',\n",
    "        y_col='label',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=4,  # 배치 크기를 줄임\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    # Convolutional Block 정의\n",
    "    def conv_block(x, filters):\n",
    "        x = Conv2D(filters, (3, 3), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        return x\n",
    "\n",
    "    # Residual Block 정의\n",
    "    def residual_block(x, filters):\n",
    "        shortcut = x\n",
    "        x = Conv2D(filters, (3, 3), padding='same', strides=(1, 1))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Conv2D(filters, (3, 3), padding='same', strides=(1, 1))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.keras.layers.add([x, shortcut])\n",
    "        x = LeakyReLU()(x)\n",
    "        return x\n",
    "\n",
    "    # Channel Attention Module 정의\n",
    "    def channel_attention(x):\n",
    "        avg_pool = GlobalAveragePooling2D()(x)\n",
    "        max_pool = GlobalAveragePooling2D()(x)\n",
    "        dense_avg = Dense(x.shape[-1], activation='relu', kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')(avg_pool)\n",
    "        dense_max = Dense(x.shape[-1], activation='relu', kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')(max_pool)\n",
    "        combined = tf.keras.layers.add([dense_avg, dense_max])\n",
    "        channel_attention = Activation('sigmoid')(combined)\n",
    "        return tf.keras.layers.multiply([x, channel_attention])\n",
    "\n",
    "    # Spatial Attention Module 정의\n",
    "    def spatial_attention(x):\n",
    "        avg_pool = tf.reduce_mean(x, axis=-1, keepdims=True)\n",
    "        max_pool = tf.reduce_max(x, axis=-1, keepdims=True)\n",
    "        combined = Concatenate(axis=-1)([avg_pool, max_pool])\n",
    "        spatial_attention = Conv2D(1, (7, 7), padding='same', activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(combined)\n",
    "        return tf.keras.layers.multiply([x, spatial_attention])\n",
    "\n",
    "    # CBAM Block 정의\n",
    "    def cbam_block(x):\n",
    "        x = channel_attention(x)\n",
    "        x = spatial_attention(x)\n",
    "        return x\n",
    "\n",
    "    # Stage 1 정의\n",
    "    def stage1(input_tensor):\n",
    "        x = conv_block(input_tensor, 32)\n",
    "        x = conv_block(x, 32)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "        x = UpSampling2D((4, 4), interpolation='bilinear')(x)  \n",
    "        return x\n",
    "\n",
    "    # Stage 2 정의\n",
    "    def stage2(input_tensor):\n",
    "        x = conv_block(input_tensor, 64)\n",
    "        x = cbam_block(x)\n",
    "        x = residual_block(x, 64)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "        x = UpSampling2D((4, 4), interpolation='bilinear')(x)  \n",
    "        return x\n",
    "\n",
    "    # Stage 3 정의\n",
    "    def stage3(input_tensor):\n",
    "        x = conv_block(input_tensor, 128)\n",
    "        x = cbam_block(x)\n",
    "        x = residual_block(x, 128)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "        x = UpSampling2D((4, 4), interpolation='bilinear')(x)  \n",
    "        return x\n",
    "\n",
    "    # 모델 구성\n",
    "    input_tensor = Input(shape=(224, 224, 3))\n",
    "\n",
    "    stage1_output = stage1(input_tensor)\n",
    "    stage2_output = stage2(stage1_output)\n",
    "    stage3_output = stage3(stage2_output)\n",
    "\n",
    "    #concatenated = Concatenate()([stage1_output, stage2_output, stage3_output])\n",
    "\n",
    "    x = GlobalAveragePooling2D()(stage3_output)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    output = Dense(4, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=output)\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 모델 학습\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=100,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=len(val_generator)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 학습 결과 시각화\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(100)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1 summary\n",
    "stage1_output = stage1(input_tensor)\n",
    "stage1_model = Model(inputs=input_tensor, outputs=stage1_output)\n",
    "print(\"Stage 1 Summary:\")\n",
    "stage1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2 summary\n",
    "stage2_output = stage2(stage1_output)\n",
    "stage2_model = Model(inputs=input_tensor, outputs=stage2_output)\n",
    "print(\"\\nStage 2 Summary:\")\n",
    "stage2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 3 summary\n",
    "stage3_output = stage3(stage2_output)\n",
    "stage3_model = Model(inputs=input_tensor, outputs=stage3_output)\n",
    "print(\"\\nStage 3 Summary:\")\n",
    "stage3_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
