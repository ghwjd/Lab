{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gpu 메모리 부족 현상이 발생해서 이에 대한 새로운 접근\n",
    "mini_batch size: 24->12  \n",
    "upsampling: (4,4) -> (2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 16:23:56.912379: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-04 16:23:57.036584: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPUs will likely run quickly with dtype policy mixed_float16 as they all have compute capability of at least 7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "# mixed precision 설정\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "# GPU 설정\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  4\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기 및 클래스 지정과 분할  \n",
    "The numbers of samples in each class for the test set are distributed as 106 (normal), 24 (AOM), 13 (CSOM), 28 (Earwax), and 20 (Other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 데이터셋의 루트 디렉토리\n",
    "dataset_directory = '/home/jeonk636/ear_classification/eardrumDs'\n",
    "\n",
    "# 클래스 이름 및 라벨을 매핑하기 위한 딕셔너리 생성\n",
    "# normal:0, Aom:1, Chornic:2, Earwax:3, Others:4\n",
    "label_map = {\n",
    "    'Aom': 1,\n",
    "    'Chornic': 2,\n",
    "    'Earwax': 3,\n",
    "    'Normal': 0,\n",
    "}\n",
    "\n",
    "# 이미지 파일 경로 및 라벨을 저장할 리스트\n",
    "image_paths = []\n",
    "image_labels = []\n",
    "\n",
    "exclude_folders = {'OtitExterna', 'tympanoskleros', 'Earventulation', 'Foreign', 'PseduoMembran'}\n",
    "\n",
    "# 각 폴더에 대해 이미지 파일 경로 및 해당 라벨을 리스트에 추가\n",
    "for label_folder in os.listdir(dataset_directory):\n",
    "    if label_folder in exclude_folders:  # 이 폴더는 건너뛴다.\n",
    "        continue\n",
    "    folder_path = os.path.join(dataset_directory, label_folder)\n",
    "    \n",
    "    for image_filename in os.listdir(folder_path):\n",
    "        # 폴더 내 파일이 실제 파일인지 확인하고 '.ipynb_checkpoints' 폴더를 건너뛴다.\n",
    "        full_path = os.path.join(folder_path, image_filename)\n",
    "        if os.path.isfile(full_path) and '.ipynb_checkpoints' not in full_path:\n",
    "            image_paths.append(full_path)\n",
    "            image_labels.append(label_map[label_folder])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal: 534\n",
      "Aom: 119\n",
      "Chornic: 63\n",
      "Earwax: 140\n"
     ]
    }
   ],
   "source": [
    "label_0_count = image_labels.count(0)\n",
    "label_1_count = image_labels.count(1)\n",
    "label_2_count = image_labels.count(2)\n",
    "label_3_count = image_labels.count(3)\n",
    "\n",
    "print('Normal:', label_0_count)\n",
    "print('Aom:', label_1_count)\n",
    "print('Chornic:', label_2_count)\n",
    "print('Earwax:', label_3_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# 이미지 경로와 라벨을 Numpy 배열로 변환\n",
    "image_paths = np.array(image_paths)\n",
    "image_labels = np.array(image_labels)\n",
    "\n",
    "# 데이터프레임으로 변환\n",
    "data = pd.DataFrame({'image_path': image_paths, 'label': image_labels})\n",
    "\n",
    "# 클래스별로 지정된 수의 샘플을 추출하여 테스트 세트로 사용(4:20 #other)\n",
    "test_counts = {\n",
    "    0: 106,  # Normal\n",
    "    1: 24,   # AOM\n",
    "    2: 13,   # CSOM\n",
    "    3: 28   # Earwax\n",
    "}\n",
    "\n",
    "test_data_list = []\n",
    "\n",
    "for label, count in test_counts.items():\n",
    "    class_data = data[data['label'] == label]\n",
    "    if len(class_data) < count:\n",
    "        raise ValueError(f\"Not enough samples for class {label}. Needed {count}, but only {len(class_data)} available.\")\n",
    "    test_data_list.append(class_data.sample(n=count, random_state=42))\n",
    "\n",
    "test_data = pd.concat(test_data_list)\n",
    "\n",
    "# 나머지 데이터를 훈련 세트로 사용\n",
    "train_data = data.drop(test_data.index)\n",
    "\n",
    "# 훈련 세트와 테스트 세트로 나누기\n",
    "x_train = train_data['image_path'].values\n",
    "y_train = train_data['label'].values\n",
    "x_test = test_data['image_path'].values\n",
    "y_test = test_data['label'].values\n",
    "\n",
    "# # train 8: validation 2 분할\n",
    "# x_train, x_test, y_train, y_test = train_test_split(\n",
    "#     image_paths, image_labels, stratify=image_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Train set:\", len(x_train))\n",
    "# print(\"test set:\", len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 685\n",
      "Test set size: 171\n",
      "Test set class distribution:\n",
      " label\n",
      "0    106\n",
      "3     28\n",
      "1     24\n",
      "2     13\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(\"Training set size:\", len(x_train))\n",
    "print(\"Test set size:\", len(x_test))\n",
    "print(\"Test set class distribution:\\n\", test_data['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras을 사용한 데이터 증강  \n",
    "224 by 224  \n",
    "Normal 클래스가 가장 많은 샘플 수를 가지고 있으므로, 이를 기준으로 AOM, CSOM, Earwax 클래스을 각각 3배, 7배, 3배 증강  \n",
    "증강을 하면 train set에 있는 total sample 수는 normal 428, Aom 380, Csom 400, Earwax 448 으로 각 클래스가 비슷해짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 레이블을 문자열로 변환\n",
    "train_data['label'] = train_data['label'].astype(str)\n",
    "test_data['label'] = test_data['label'].astype(str)\n",
    "\n",
    "# 데이터 증강 파라미터 정의\n",
    "data_gen_args = dict(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.7, 1.3],  # ±30% 밝기 조절\n",
    "    width_shift_range=0.2,  # 좌우 이동 범위 20%\n",
    "    height_shift_range=0.2,  # 상하 이동 범위 20%\n",
    "    zoom_range=0.2,  # ±20% 확대/축소\n",
    "    rotation_range=20  # ±20도 회전\n",
    ")\n",
    "\n",
    "# 데이터 증강 제네레이터 생성\n",
    "datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "# 증강된 샘플 수를 지정(4:4 #Other)\n",
    "augment_counts = {\n",
    "    1: 3,  # AOM\n",
    "    2: 7,  # CSOM\n",
    "    3: 3  # Earwax\n",
    "}\n",
    "\n",
    "# 증강된 데이터를 저장할 리스트\n",
    "augmented_data = []\n",
    "\n",
    "for label, count in augment_counts.items():\n",
    "    class_data = train_data[train_data['label'] == str(label)]\n",
    "    for i in range(count):\n",
    "        for index, row in class_data.iterrows():\n",
    "            img = tf.keras.preprocessing.image.load_img(row['image_path'], target_size=(224, 224))\n",
    "            img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "            augmented_iter = datagen.flow(img_array, batch_size=1)\n",
    "            augmented_img = next(augmented_iter)[0].astype(np.uint8)\n",
    "            augmented_data.append({'image_path': row['image_path'], 'label': row['label']})\n",
    "            \n",
    "# 원본 데이터와 증강 데이터를 결합\n",
    "augmented_df = pd.DataFrame(augmented_data)\n",
    "train_data = pd.concat([train_data, augmented_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "3    448\n",
      "0    428\n",
      "2    400\n",
      "1    380\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "2    350\n",
      "3    336\n",
      "1    285\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "print(train_data['label'].value_counts())\n",
    "print(augmented_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Found 1656 validated image filenames belonging to 4 classes.\n",
      "Found 171 validated image filenames belonging to 4 classes.\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 16:24:16.416003: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-04 16:24:18.079340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14825 MB memory:  -> device: 0, name: Quadro RTX 5000, pci bus id: 0000:3b:00.0, compute capability: 7.5\n",
      "2024-06-04 16:24:18.080415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14825 MB memory:  -> device: 1, name: Quadro RTX 5000, pci bus id: 0000:5e:00.0, compute capability: 7.5\n",
      "2024-06-04 16:24:18.081372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 14825 MB memory:  -> device: 2, name: Quadro RTX 5000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "2024-06-04 16:24:18.082314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 14825 MB memory:  -> device: 3, name: Quadro RTX 5000, pci bus id: 0000:af:00.0, compute capability: 7.5\n",
      "2024-06-04 16:24:18.820842: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorDataset/_1\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\017TensorDataset:0\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 46 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 46 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 16:24:39.871052: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8907\n",
      "2024-06-04 16:24:40.182283: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8907\n",
      "2024-06-04 16:24:40.548182: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-06-04 16:24:40.551747: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-06-04 16:24:41.010195: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-06-04 16:24:44.388161: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x5577bc699c50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-04 16:24:44.388225: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Quadro RTX 5000, Compute Capability 7.5\n",
      "2024-06-04 16:24:44.388241: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): Quadro RTX 5000, Compute Capability 7.5\n",
      "2024-06-04 16:24:44.388253: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): Quadro RTX 5000, Compute Capability 7.5\n",
      "2024-06-04 16:24:44.388263: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (3): Quadro RTX 5000, Compute Capability 7.5\n",
      "2024-06-04 16:24:44.400775: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-04 16:24:44.476419: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-06-04 16:24:44.476537: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-06-04 16:24:44.540919: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-06-04 16:24:44.616169: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-06-04 16:24:44.749482: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-06-04 16:24:44.942927: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-06-04 16:24:45.295014: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-06-04 16:24:45.896752: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-06-04 16:24:46.930410: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-06-04 16:24:47.174952: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2024-06-04 16:24:47.470182: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "828/828 [==============================] - ETA: 0s - loss: 1.3591 - accuracy: 0.3140"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 16:25:27.817751: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorDataset/_1\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\020TensorDataset:40\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "828/828 [==============================] - 73s 50ms/step - loss: 1.3591 - accuracy: 0.3140 - val_loss: 1.5980 - val_accuracy: 0.1988\n",
      "Epoch 2/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 1.2819 - accuracy: 0.4173 - val_loss: 1.4923 - val_accuracy: 0.2339\n",
      "Epoch 3/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 1.2326 - accuracy: 0.4463 - val_loss: 1.2030 - val_accuracy: 0.5789\n",
      "Epoch 4/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 1.1875 - accuracy: 0.4801 - val_loss: 1.2176 - val_accuracy: 0.5380\n",
      "Epoch 5/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 1.1374 - accuracy: 0.5048 - val_loss: 1.0949 - val_accuracy: 0.7251\n",
      "Epoch 6/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 1.1035 - accuracy: 0.5187 - val_loss: 1.1878 - val_accuracy: 0.5380\n",
      "Epoch 7/100\n",
      "828/828 [==============================] - 39s 48ms/step - loss: 1.0770 - accuracy: 0.5211 - val_loss: 1.1309 - val_accuracy: 0.5965\n",
      "Epoch 8/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 1.0685 - accuracy: 0.5223 - val_loss: 1.1345 - val_accuracy: 0.5789\n",
      "Epoch 9/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 1.0491 - accuracy: 0.5447 - val_loss: 1.0081 - val_accuracy: 0.7076\n",
      "Epoch 10/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 1.0248 - accuracy: 0.5483 - val_loss: 1.7516 - val_accuracy: 0.3684\n",
      "Epoch 11/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 1.0150 - accuracy: 0.5676 - val_loss: 1.1005 - val_accuracy: 0.6257\n",
      "Epoch 12/100\n",
      "828/828 [==============================] - 39s 48ms/step - loss: 1.0045 - accuracy: 0.5562 - val_loss: 1.3753 - val_accuracy: 0.2632\n",
      "Epoch 13/100\n",
      "828/828 [==============================] - 39s 48ms/step - loss: 1.0031 - accuracy: 0.5688 - val_loss: 1.0712 - val_accuracy: 0.6491\n",
      "Epoch 14/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 0.9679 - accuracy: 0.5755 - val_loss: 1.2192 - val_accuracy: 0.3333\n",
      "Epoch 15/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 0.9526 - accuracy: 0.5882 - val_loss: 1.1480 - val_accuracy: 0.4795\n",
      "Epoch 16/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 0.9473 - accuracy: 0.5833 - val_loss: 1.1908 - val_accuracy: 0.4094\n",
      "Epoch 17/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 0.9214 - accuracy: 0.5888 - val_loss: 1.1817 - val_accuracy: 0.2807\n",
      "Epoch 18/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 0.9290 - accuracy: 0.5888 - val_loss: 1.0050 - val_accuracy: 0.6959\n",
      "Epoch 19/100\n",
      "828/828 [==============================] - 39s 48ms/step - loss: 0.8975 - accuracy: 0.6045 - val_loss: 1.0656 - val_accuracy: 0.6784\n",
      "Epoch 20/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 0.9025 - accuracy: 0.6057 - val_loss: 1.2645 - val_accuracy: 0.3392\n",
      "Epoch 21/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 0.8835 - accuracy: 0.6014 - val_loss: 1.0514 - val_accuracy: 0.6316\n",
      "Epoch 22/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 0.8844 - accuracy: 0.6141 - val_loss: 1.1727 - val_accuracy: 0.4737\n",
      "Epoch 23/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.8490 - accuracy: 0.6298 - val_loss: 1.1018 - val_accuracy: 0.5731\n",
      "Epoch 24/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 0.8588 - accuracy: 0.6280 - val_loss: 1.2686 - val_accuracy: 0.3450\n",
      "Epoch 25/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 0.8389 - accuracy: 0.6304 - val_loss: 1.1619 - val_accuracy: 0.5029\n",
      "Epoch 26/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 0.8338 - accuracy: 0.6341 - val_loss: 1.2794 - val_accuracy: 0.2924\n",
      "Epoch 27/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 0.8316 - accuracy: 0.6341 - val_loss: 1.2347 - val_accuracy: 0.3275\n",
      "Epoch 28/100\n",
      "828/828 [==============================] - 39s 48ms/step - loss: 0.8134 - accuracy: 0.6612 - val_loss: 1.1604 - val_accuracy: 0.4561\n",
      "Epoch 29/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 0.8160 - accuracy: 0.6407 - val_loss: 1.3694 - val_accuracy: 0.2164\n",
      "Epoch 30/100\n",
      "828/828 [==============================] - 38s 46ms/step - loss: 0.7874 - accuracy: 0.6461 - val_loss: 1.4349 - val_accuracy: 0.1462\n",
      "Epoch 31/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 0.7862 - accuracy: 0.6649 - val_loss: 1.1391 - val_accuracy: 0.5614\n",
      "Epoch 32/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 0.7826 - accuracy: 0.6703 - val_loss: 1.2410 - val_accuracy: 0.3684\n",
      "Epoch 33/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 0.7609 - accuracy: 0.6884 - val_loss: 1.4856 - val_accuracy: 0.1813\n",
      "Epoch 34/100\n",
      "828/828 [==============================] - 39s 48ms/step - loss: 0.7468 - accuracy: 0.6842 - val_loss: 1.3718 - val_accuracy: 0.2339\n",
      "Epoch 35/100\n",
      "828/828 [==============================] - 39s 48ms/step - loss: 0.7377 - accuracy: 0.7065 - val_loss: 1.2954 - val_accuracy: 0.3450\n",
      "Epoch 36/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 0.7206 - accuracy: 0.6957 - val_loss: 1.3734 - val_accuracy: 0.3509\n",
      "Epoch 37/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 0.6955 - accuracy: 0.7295 - val_loss: 1.6439 - val_accuracy: 0.1871\n",
      "Epoch 38/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.6592 - accuracy: 0.7361 - val_loss: 1.4516 - val_accuracy: 0.3275\n",
      "Epoch 39/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.6729 - accuracy: 0.7271 - val_loss: 1.4650 - val_accuracy: 0.2573\n",
      "Epoch 40/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.6554 - accuracy: 0.7512 - val_loss: 1.8001 - val_accuracy: 0.2222\n",
      "Epoch 41/100\n",
      "828/828 [==============================] - 39s 48ms/step - loss: 0.6438 - accuracy: 0.7566 - val_loss: 1.4159 - val_accuracy: 0.3450\n",
      "Epoch 42/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 0.6457 - accuracy: 0.7446 - val_loss: 1.6659 - val_accuracy: 0.1988\n",
      "Epoch 43/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 0.6069 - accuracy: 0.7687 - val_loss: 1.5371 - val_accuracy: 0.3041\n",
      "Epoch 44/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.5990 - accuracy: 0.7705 - val_loss: 1.7344 - val_accuracy: 0.1930\n",
      "Epoch 45/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 0.5708 - accuracy: 0.7766 - val_loss: 1.7061 - val_accuracy: 0.2281\n",
      "Epoch 46/100\n",
      "828/828 [==============================] - 39s 48ms/step - loss: 0.5712 - accuracy: 0.7766 - val_loss: 1.8941 - val_accuracy: 0.1871\n",
      "Epoch 47/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.5541 - accuracy: 0.7971 - val_loss: 1.9853 - val_accuracy: 0.1696\n",
      "Epoch 48/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.5462 - accuracy: 0.7953 - val_loss: 1.8037 - val_accuracy: 0.2456\n",
      "Epoch 49/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.5519 - accuracy: 0.7983 - val_loss: 2.4576 - val_accuracy: 0.1287\n",
      "Epoch 50/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.5052 - accuracy: 0.8080 - val_loss: 2.2186 - val_accuracy: 0.1579\n",
      "Epoch 51/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 0.5275 - accuracy: 0.8080 - val_loss: 1.7790 - val_accuracy: 0.2632\n",
      "Epoch 52/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.4609 - accuracy: 0.8333 - val_loss: 2.0889 - val_accuracy: 0.1813\n",
      "Epoch 53/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 0.4634 - accuracy: 0.8370 - val_loss: 1.8145 - val_accuracy: 0.2398\n",
      "Epoch 54/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 0.4775 - accuracy: 0.8170 - val_loss: 1.4776 - val_accuracy: 0.3684\n",
      "Epoch 55/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 0.4437 - accuracy: 0.8424 - val_loss: 1.6911 - val_accuracy: 0.2807\n",
      "Epoch 56/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.4503 - accuracy: 0.8364 - val_loss: 2.2954 - val_accuracy: 0.1345\n",
      "Epoch 57/100\n",
      "828/828 [==============================] - 39s 48ms/step - loss: 0.4701 - accuracy: 0.8140 - val_loss: 2.0473 - val_accuracy: 0.1871\n",
      "Epoch 58/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.4180 - accuracy: 0.8448 - val_loss: 1.7415 - val_accuracy: 0.2456\n",
      "Epoch 59/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.4366 - accuracy: 0.8351 - val_loss: 1.7859 - val_accuracy: 0.2398\n",
      "Epoch 60/100\n",
      "828/828 [==============================] - 39s 48ms/step - loss: 0.3991 - accuracy: 0.8587 - val_loss: 2.3502 - val_accuracy: 0.1579\n",
      "Epoch 61/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.4194 - accuracy: 0.8502 - val_loss: 1.8914 - val_accuracy: 0.2573\n",
      "Epoch 62/100\n",
      "828/828 [==============================] - 39s 48ms/step - loss: 0.4175 - accuracy: 0.8478 - val_loss: 1.7057 - val_accuracy: 0.2807\n",
      "Epoch 63/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.3979 - accuracy: 0.8533 - val_loss: 1.9201 - val_accuracy: 0.2573\n",
      "Epoch 64/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.3821 - accuracy: 0.8623 - val_loss: 2.2601 - val_accuracy: 0.1462\n",
      "Epoch 65/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.3888 - accuracy: 0.8575 - val_loss: 2.0166 - val_accuracy: 0.2105\n",
      "Epoch 66/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.4183 - accuracy: 0.8563 - val_loss: 1.7472 - val_accuracy: 0.3392\n",
      "Epoch 67/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.3897 - accuracy: 0.8521 - val_loss: 1.8329 - val_accuracy: 0.2339\n",
      "Epoch 68/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.3865 - accuracy: 0.8593 - val_loss: 1.9063 - val_accuracy: 0.2749\n",
      "Epoch 69/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.3465 - accuracy: 0.8835 - val_loss: 1.9835 - val_accuracy: 0.2164\n",
      "Epoch 70/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.3817 - accuracy: 0.8551 - val_loss: 1.7730 - val_accuracy: 0.2865\n",
      "Epoch 71/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.3548 - accuracy: 0.8659 - val_loss: 1.8531 - val_accuracy: 0.2749\n",
      "Epoch 72/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.3409 - accuracy: 0.8708 - val_loss: 1.9347 - val_accuracy: 0.2456\n",
      "Epoch 73/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.3487 - accuracy: 0.8671 - val_loss: 1.9684 - val_accuracy: 0.2807\n",
      "Epoch 74/100\n",
      "828/828 [==============================] - 39s 48ms/step - loss: 0.3350 - accuracy: 0.8792 - val_loss: 2.2459 - val_accuracy: 0.2222\n",
      "Epoch 75/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 0.3366 - accuracy: 0.8774 - val_loss: 2.4314 - val_accuracy: 0.1637\n",
      "Epoch 76/100\n",
      "828/828 [==============================] - 39s 48ms/step - loss: 0.3302 - accuracy: 0.8798 - val_loss: 2.2860 - val_accuracy: 0.2281\n",
      "Epoch 77/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.3218 - accuracy: 0.8883 - val_loss: 2.0574 - val_accuracy: 0.2690\n",
      "Epoch 78/100\n",
      "828/828 [==============================] - 39s 48ms/step - loss: 0.3282 - accuracy: 0.8780 - val_loss: 2.1359 - val_accuracy: 0.1871\n",
      "Epoch 79/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.3267 - accuracy: 0.8804 - val_loss: 2.7826 - val_accuracy: 0.1345\n",
      "Epoch 80/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.3338 - accuracy: 0.8847 - val_loss: 1.9052 - val_accuracy: 0.2924\n",
      "Epoch 81/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.3336 - accuracy: 0.8804 - val_loss: 2.4934 - val_accuracy: 0.1228\n",
      "Epoch 82/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.2862 - accuracy: 0.8967 - val_loss: 1.6762 - val_accuracy: 0.3392\n",
      "Epoch 83/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.2944 - accuracy: 0.8907 - val_loss: 1.7235 - val_accuracy: 0.3684\n",
      "Epoch 84/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.2980 - accuracy: 0.8853 - val_loss: 2.0015 - val_accuracy: 0.2865\n",
      "Epoch 85/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.2868 - accuracy: 0.8925 - val_loss: 2.2180 - val_accuracy: 0.2281\n",
      "Epoch 86/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.2728 - accuracy: 0.9010 - val_loss: 2.2554 - val_accuracy: 0.2222\n",
      "Epoch 87/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.2963 - accuracy: 0.8967 - val_loss: 2.2957 - val_accuracy: 0.2281\n",
      "Epoch 88/100\n",
      "828/828 [==============================] - 39s 48ms/step - loss: 0.2856 - accuracy: 0.8955 - val_loss: 2.2786 - val_accuracy: 0.2281\n",
      "Epoch 89/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.2772 - accuracy: 0.8973 - val_loss: 2.0932 - val_accuracy: 0.2690\n",
      "Epoch 90/100\n",
      "828/828 [==============================] - 39s 48ms/step - loss: 0.2914 - accuracy: 0.8949 - val_loss: 1.7496 - val_accuracy: 0.4035\n",
      "Epoch 91/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.2830 - accuracy: 0.9034 - val_loss: 1.8286 - val_accuracy: 0.3099\n",
      "Epoch 92/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.2693 - accuracy: 0.9034 - val_loss: 2.1835 - val_accuracy: 0.2690\n",
      "Epoch 93/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.2628 - accuracy: 0.9040 - val_loss: 2.3852 - val_accuracy: 0.2222\n",
      "Epoch 94/100\n",
      "828/828 [==============================] - 39s 48ms/step - loss: 0.2775 - accuracy: 0.8998 - val_loss: 2.6044 - val_accuracy: 0.2105\n",
      "Epoch 95/100\n",
      "828/828 [==============================] - 39s 48ms/step - loss: 0.2886 - accuracy: 0.8907 - val_loss: 1.8709 - val_accuracy: 0.3099\n",
      "Epoch 96/100\n",
      "828/828 [==============================] - 40s 48ms/step - loss: 0.2736 - accuracy: 0.9094 - val_loss: 1.6225 - val_accuracy: 0.4386\n",
      "Epoch 97/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 0.2739 - accuracy: 0.8973 - val_loss: 1.8511 - val_accuracy: 0.3567\n",
      "Epoch 98/100\n",
      "828/828 [==============================] - 39s 47ms/step - loss: 0.2655 - accuracy: 0.9040 - val_loss: 2.3122 - val_accuracy: 0.2982\n",
      "Epoch 99/100\n",
      "828/828 [==============================] - 39s 48ms/step - loss: 0.2618 - accuracy: 0.9028 - val_loss: 2.0238 - val_accuracy: 0.3275\n",
      "Epoch 100/100\n",
      "828/828 [==============================] - 39s 48ms/step - loss: 0.2441 - accuracy: 0.9070 - val_loss: 2.1661 - val_accuracy: 0.2690\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, GlobalAveragePooling2D, Dense, Dropout, BatchNormalization, Activation, Input, LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# logical_gpus = tf.config.experimental.list_logical_devices ('GPU')\n",
    "# strategy = tf.distribute.MirroredStrategy(logical_gpus)\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    # 데이터 증강 설정\n",
    "    data_gen_args = dict(\n",
    "        rescale=1./255,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        brightness_range=[0.7, 1.3],\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.2\n",
    "    )\n",
    "\n",
    "    # 데이터 증강 생성기\n",
    "    train_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # 데이터 증강 적용 (train_data는 데이터프레임 형태라고 가정)\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_data,\n",
    "        x_col='image_path',\n",
    "        y_col='label',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=2,  # 배치 크기를 줄임\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    val_generator = test_datagen.flow_from_dataframe(\n",
    "        dataframe=test_data,\n",
    "        x_col='image_path',\n",
    "        y_col='label',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=2,  # 배치 크기를 줄임\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    # Convolutional Block 정의\n",
    "    def conv_block(x, filters):\n",
    "        x = Conv2D(filters, (3, 3), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        return x\n",
    "\n",
    "    # Residual Block 정의\n",
    "    def residual_block(x, filters):\n",
    "        shortcut = x\n",
    "        x = Conv2D(filters, (3, 3), padding='same', strides=(1, 1))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU()(x)\n",
    "        x = Conv2D(filters, (3, 3), padding='same', strides=(1, 1))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.keras.layers.add([x, shortcut])\n",
    "        x = LeakyReLU()(x)\n",
    "        return x\n",
    "\n",
    "    # Channel Attention Module 정의\n",
    "    def channel_attention(x):\n",
    "        avg_pool = GlobalAveragePooling2D()(x)\n",
    "        max_pool = GlobalAveragePooling2D()(x)\n",
    "        dense_avg = Dense(x.shape[-1], activation='relu', kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')(avg_pool)\n",
    "        dense_max = Dense(x.shape[-1], activation='relu', kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')(max_pool)\n",
    "        combined = tf.keras.layers.add([dense_avg, dense_max])\n",
    "        channel_attention = Activation('sigmoid')(combined)\n",
    "        return tf.keras.layers.multiply([x, channel_attention])\n",
    "\n",
    "    # Spatial Attention Module 정의\n",
    "    def spatial_attention(x):\n",
    "        avg_pool = tf.reduce_mean(x, axis=-1, keepdims=True)\n",
    "        max_pool = tf.reduce_max(x, axis=-1, keepdims=True)\n",
    "        combined = Concatenate(axis=-1)([avg_pool, max_pool])\n",
    "        spatial_attention = Conv2D(1, (7, 7), padding='same', activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(combined)\n",
    "        return tf.keras.layers.multiply([x, spatial_attention])\n",
    "\n",
    "    # CBAM Block 정의\n",
    "    def cbam_block(x):\n",
    "        x = channel_attention(x)\n",
    "        x = spatial_attention(x)\n",
    "        return x\n",
    "\n",
    "    # Stage 1 정의\n",
    "    def stage1(input_tensor):\n",
    "        x = conv_block(input_tensor, 32)\n",
    "        x = conv_block(x, 32)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "        x = UpSampling2D((2, 2), interpolation='bilinear')(x)  # Output shape: (224, 224, 32)\n",
    "        return x\n",
    "\n",
    "    # Stage 2 정의\n",
    "    def stage2(input_tensor):\n",
    "        x = conv_block(input_tensor, 64)\n",
    "        x = cbam_block(x)\n",
    "        x = residual_block(x, 64)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "        x = UpSampling2D((2, 2), interpolation='bilinear')(x)  # Output shape: (224, 224, 64)\n",
    "        return x\n",
    "\n",
    "    # Stage 3 정의\n",
    "    def stage3(input_tensor):\n",
    "        x = conv_block(input_tensor, 128)\n",
    "        x = cbam_block(x)\n",
    "        x = residual_block(x, 128)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "        x = UpSampling2D((2, 2), interpolation='bilinear')(x)  # Output shape: (224, 224, 128)\n",
    "        return x\n",
    "\n",
    "    # 모델 구성\n",
    "    input_tensor = Input(shape=(224, 224, 3))\n",
    "\n",
    "    stage1_output = stage1(input_tensor)\n",
    "    stage2_output = stage2(stage1_output)\n",
    "    stage3_output = stage3(stage2_output)\n",
    "\n",
    "    concatenated = Concatenate()([stage1_output, stage2_output, stage3_output])\n",
    "\n",
    "    x = GlobalAveragePooling2D()(concatenated)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    output = Dense(4, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=output)\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=100,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=len(val_generator)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 Summary:\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 224, 224, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 224, 224, 32)     128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 224, 224, 32)      0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 224, 224, 32)      9248      \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 224, 224, 32)     128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 224, 224, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 112, 112, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " up_sampling2d_3 (UpSampling  (None, 224, 224, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,400\n",
      "Trainable params: 10,272\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Stage 1 summary\n",
    "stage1_output = stage1(input_tensor)\n",
    "stage1_model = Model(inputs=input_tensor, outputs=stage1_output)\n",
    "print(\"Stage 1 Summary:\")\n",
    "stage1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stage 2 Summary:\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 224, 224, 32  896         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 224, 224, 32  128        ['conv2d_10[0][0]']              \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 224, 224, 32  0           ['batch_normalization_8[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 224, 224, 32  9248        ['activation_6[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 224, 224, 32  128        ['conv2d_11[0][0]']              \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 224, 224, 32  0           ['batch_normalization_9[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 112, 112, 32  0          ['activation_7[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 224, 224, 32  0          ['max_pooling2d_3[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 224, 224, 64  18496       ['up_sampling2d_3[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 224, 224, 64  256        ['conv2d_12[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 224, 224, 64  0           ['batch_normalization_10[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_5 (Gl  (None, 64)          0           ['activation_8[0][0]']           \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling2d_6 (Gl  (None, 64)          0           ['activation_8[0][0]']           \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 64)           4160        ['global_average_pooling2d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 64)           4160        ['global_average_pooling2d_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 64)           0           ['dense_6[0][0]',                \n",
      "                                                                  'dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 64)           0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)          (None, 224, 224, 64  0           ['activation_8[0][0]',           \n",
      "                                )                                 'activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_2 (TFOpLam  (None, 224, 224, 1)  0          ['multiply_4[0][0]']             \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_2 (TFOpLamb  (None, 224, 224, 1)  0          ['multiply_4[0][0]']             \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 224, 224, 2)  0           ['tf.math.reduce_mean_2[0][0]',  \n",
      "                                                                  'tf.math.reduce_max_2[0][0]']   \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 224, 224, 1)  98          ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_5 (Multiply)          (None, 224, 224, 64  0           ['multiply_4[0][0]',             \n",
      "                                )                                 'conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 224, 224, 64  36928       ['multiply_5[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 224, 224, 64  256        ['conv2d_14[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 224, 224, 64  0           ['batch_normalization_11[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 224, 224, 64  36928       ['leaky_re_lu_4[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 224, 224, 64  256        ['conv2d_15[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 224, 224, 64  0           ['batch_normalization_12[0][0]', \n",
      "                                )                                 'multiply_5[0][0]']             \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 224, 224, 64  0           ['add_5[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 112, 112, 64  0          ['leaky_re_lu_5[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 64  0          ['max_pooling2d_4[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 111,938\n",
      "Trainable params: 111,426\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Stage 2 summary\n",
    "stage2_output = stage2(stage1_output)\n",
    "stage2_model = Model(inputs=input_tensor, outputs=stage2_output)\n",
    "print(\"\\nStage 2 Summary:\")\n",
    "stage2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stage 3 Summary:\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 224, 224, 32  896         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 224, 224, 32  128        ['conv2d_10[0][0]']              \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 224, 224, 32  0           ['batch_normalization_8[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 224, 224, 32  9248        ['activation_6[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 224, 224, 32  128        ['conv2d_11[0][0]']              \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 224, 224, 32  0           ['batch_normalization_9[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 112, 112, 32  0          ['activation_7[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 224, 224, 32  0          ['max_pooling2d_3[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 224, 224, 64  18496       ['up_sampling2d_3[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 224, 224, 64  256        ['conv2d_12[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 224, 224, 64  0           ['batch_normalization_10[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_5 (Gl  (None, 64)          0           ['activation_8[0][0]']           \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling2d_6 (Gl  (None, 64)          0           ['activation_8[0][0]']           \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 64)           4160        ['global_average_pooling2d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 64)           4160        ['global_average_pooling2d_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 64)           0           ['dense_6[0][0]',                \n",
      "                                                                  'dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 64)           0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)          (None, 224, 224, 64  0           ['activation_8[0][0]',           \n",
      "                                )                                 'activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_2 (TFOpLam  (None, 224, 224, 1)  0          ['multiply_4[0][0]']             \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_2 (TFOpLamb  (None, 224, 224, 1)  0          ['multiply_4[0][0]']             \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 224, 224, 2)  0           ['tf.math.reduce_mean_2[0][0]',  \n",
      "                                                                  'tf.math.reduce_max_2[0][0]']   \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 224, 224, 1)  98          ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_5 (Multiply)          (None, 224, 224, 64  0           ['multiply_4[0][0]',             \n",
      "                                )                                 'conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 224, 224, 64  36928       ['multiply_5[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 224, 224, 64  256        ['conv2d_14[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 224, 224, 64  0           ['batch_normalization_11[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 224, 224, 64  36928       ['leaky_re_lu_4[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 224, 224, 64  256        ['conv2d_15[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 224, 224, 64  0           ['batch_normalization_12[0][0]', \n",
      "                                )                                 'multiply_5[0][0]']             \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 224, 224, 64  0           ['add_5[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 112, 112, 64  0          ['leaky_re_lu_5[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 64  0          ['max_pooling2d_4[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 224, 224, 12  73856       ['up_sampling2d_4[0][0]']        \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 224, 224, 12  512        ['conv2d_16[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 224, 224, 12  0           ['batch_normalization_13[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " global_average_pooling2d_7 (Gl  (None, 128)         0           ['activation_10[0][0]']          \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling2d_8 (Gl  (None, 128)         0           ['activation_10[0][0]']          \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 128)          16512       ['global_average_pooling2d_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 128)          16512       ['global_average_pooling2d_8[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 128)          0           ['dense_8[0][0]',                \n",
      "                                                                  'dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 128)          0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " multiply_6 (Multiply)          (None, 224, 224, 12  0           ['activation_10[0][0]',          \n",
      "                                8)                                'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_3 (TFOpLam  (None, 224, 224, 1)  0          ['multiply_6[0][0]']             \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_3 (TFOpLamb  (None, 224, 224, 1)  0          ['multiply_6[0][0]']             \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 224, 224, 2)  0           ['tf.math.reduce_mean_3[0][0]',  \n",
      "                                                                  'tf.math.reduce_max_3[0][0]']   \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 224, 224, 1)  98          ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_7 (Multiply)          (None, 224, 224, 12  0           ['multiply_6[0][0]',             \n",
      "                                8)                                'conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 224, 224, 12  147584      ['multiply_7[0][0]']             \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 224, 224, 12  512        ['conv2d_18[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 224, 224, 12  0           ['batch_normalization_14[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 224, 224, 12  147584      ['leaky_re_lu_6[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 224, 224, 12  512        ['conv2d_19[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 224, 224, 12  0           ['batch_normalization_15[0][0]', \n",
      "                                8)                                'multiply_7[0][0]']             \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 224, 224, 12  0           ['add_7[0][0]']                  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 112, 112, 12  0          ['leaky_re_lu_7[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 12  0          ['max_pooling2d_5[0][0]']        \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 515,620\n",
      "Trainable params: 514,340\n",
      "Non-trainable params: 1,280\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Stage 3 summary\n",
    "stage3_output = stage3(stage2_output)\n",
    "stage3_model = Model(inputs=input_tensor, outputs=stage3_output)\n",
    "print(\"\\nStage 3 Summary:\")\n",
    "stage3_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
